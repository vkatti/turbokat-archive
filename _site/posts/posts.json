[
  {
    "path": "posts/2022-08-29-tidyrpivotwider/",
    "title": "Pivoting your tables with Tidyr: Part II",
    "description": "Converting \"long\" to \"wide\" format",
    "author": [
      {
        "name": "Vishal Katti",
        "url": {}
      }
    ],
    "date": "2022-08-29",
    "categories": [
      "Rstats",
      "functions",
      "tidyr",
      "pivot"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nThe long one\r\nThe wide one\r\nConclusion\r\nReferences\r\n\r\nIntro\r\nThis is part 2 of the Pivoting your tables with Tidyr series. Read Part 1 here.\r\nWe discussed the advantages of using the long format during data analysis, most users feel that the wide format is more readable by human. This is why most reports tend to have the data arranged in the wide format.\r\nThe wide format has at least one column which acts as a primary key i.e.¬†it is unique and each value appears only once. It can also have multiple column whose unique combination acts as a primary key i.e.¬†each combination appears only once.\r\nRead more about wide vs.¬†long formats here.\r\nWhile the long format is preferred and is desirable for data and plotting operations using R, Python or other data processing programming languages, the wide format is more human-readable. The {tidyr} R package has functions that allow you to transform your tabular data between the two formats.\r\nIn this post, we will see how to convert a long dataframe to wide format using the pivot_wider() function from {tidyr} package.\r\nThe long one\r\nConsider the following data table. It has been created from the famous Gapminder dataset. This table shows the average life expectancy in each continent for 2 years. While some of you may say that Gapminder data contains records for a lot more number of years, here we consider just the latest 2 years for ease of explanation and visual purposes. We have added an extra id column for teaching purpose.\r\nContinent-wise Average Life Expectancy over last 2 yearsmy_data is in the long format as we have continent names and year in their own column and average life expectancy values for each unique combination of year and continent. If we want to compare life expectancy across years for each continent, we need to have the life expectancy values for each continent side-by-side for easier viewing i.e.¬†we need to convert to the wide format. To convert this tibble to the wide format, we need to push the year values into the headers and the average_life_expectancy values under the corresponding year column.\r\nThe wide one\r\nThe wide format of this table would ideally have only continent and columns having each unique value in the year column as a header. In this case, the wide one would look something like the table below.\r\n\r\nThe wide format has unique values of the column that are not pushed into headers. In this case, the continent column becomes unique for each row.\r\nLet‚Äôs recreate the above transformation in R. First, we create the my_data table.\r\n\r\n\r\nmy_data <- data.frame(\r\n  id = 1:10,\r\n  year = c(2002L, 2002L, 2002L, 2002L, 2002L, 2007L, 2007L, 2007L, 2007L, 2007L),\r\n  continent = c(\"Africa\", \"Americas\", \"Asia\", \"Europe\", \"Oceania\", \"Africa\", \r\n                \"Americas\", \"Asia\", \"Europe\", \"Oceania\"),\r\n  average_life_expectancy = c(53.33, 72.42, 69.23, 76.7, 79.74, 54.81, 73.61, 70.73, 77.65, 80.72)\r\n)\r\n\r\nknitr::kable(my_data)\r\n\r\nid\r\nyear\r\ncontinent\r\naverage_life_expectancy\r\n1\r\n2002\r\nAfrica\r\n53.33\r\n2\r\n2002\r\nAmericas\r\n72.42\r\n3\r\n2002\r\nAsia\r\n69.23\r\n4\r\n2002\r\nEurope\r\n76.70\r\n5\r\n2002\r\nOceania\r\n79.74\r\n6\r\n2007\r\nAfrica\r\n54.81\r\n7\r\n2007\r\nAmericas\r\n73.61\r\n8\r\n2007\r\nAsia\r\n70.73\r\n9\r\n2007\r\nEurope\r\n77.65\r\n10\r\n2007\r\nOceania\r\n80.72\r\n\r\nTo convert this table into wide format, we use the pivot_wider() function from {tidyr} R package. Let us see how to use this function.\r\nüí°Tip: use formals to view all the formal arguments of a function and their default values. formals returns a named list.\r\n\r\n\r\nlibrary(tidyr, quietly = TRUE, warn.conflicts = FALSE)\r\n\r\nformals(pivot_wider)\r\n\r\n$data\r\n\r\n\r\n$id_cols\r\nNULL\r\n\r\n$id_expand\r\n[1] FALSE\r\n\r\n$names_from\r\nname\r\n\r\n$names_prefix\r\n[1] \"\"\r\n\r\n$names_sep\r\n[1] \"_\"\r\n\r\n$names_glue\r\nNULL\r\n\r\n$names_sort\r\n[1] FALSE\r\n\r\n$names_vary\r\n[1] \"fastest\"\r\n\r\n$names_expand\r\n[1] FALSE\r\n\r\n$names_repair\r\n[1] \"check_unique\"\r\n\r\n$values_from\r\nvalue\r\n\r\n$values_fill\r\nNULL\r\n\r\n$values_fn\r\nNULL\r\n\r\n$unused_fn\r\nNULL\r\n\r\n$...\r\n\r\nThe result of formals(pivot_wider) tells us that the minimum information needed to use this function is to provide values to the data,names_from and values_from arguments as all other arguments have default values and hence, are optional.\r\nUsing only the minimum arguments with pivot_wider(), we get a wide formatted tibble but with missing data!\r\n\r\n\r\nwide_minimal <- pivot_wider(\r\n                        data        = my_data,\r\n                        names_from  = year,\r\n                        values_from = average_life_expectancy\r\n                        )\r\n\r\nknitr::kable(wide_minimal)\r\n\r\nid\r\ncontinent\r\n2002\r\n2007\r\n1\r\nAfrica\r\n53.33\r\nNA\r\n2\r\nAmericas\r\n72.42\r\nNA\r\n3\r\nAsia\r\n69.23\r\nNA\r\n4\r\nEurope\r\n76.70\r\nNA\r\n5\r\nOceania\r\n79.74\r\nNA\r\n6\r\nAfrica\r\nNA\r\n54.81\r\n7\r\nAmericas\r\nNA\r\n73.61\r\n8\r\nAsia\r\nNA\r\n70.73\r\n9\r\nEurope\r\nNA\r\n77.65\r\n10\r\nOceania\r\nNA\r\n80.72\r\n\r\nSo why did NAs appear in the result?\r\npivot_wider() creates unique combinations of all columns not included in names_from or values_from argument. Therefore, if your dataframe/tibble had a primary key prior to the transformation, the primary key of your transformed ‚Äúwide‚Äù dataframe is your old primary key + unique combinations of all columns not included in names_from or values_from argument. We do have id column as a primary key in the original tibble. This gives an unusable output with NAs for each combination.\r\nTo specify which column/s to be made unique, pass their name to the id_cols argument. Here we pass the continent column to the id_cols argument.\r\n\r\n\r\nmy_data_longer <- pivot_wider(\r\n                        data        = my_data,\r\n                        id_cols     = continent, \r\n                        names_from  = year,\r\n                        values_from = average_life_expectancy\r\n                        )\r\n\r\nknitr::kable(my_data_longer)\r\n\r\ncontinent\r\n2002\r\n2007\r\nAfrica\r\n53.33\r\n54.81\r\nAmericas\r\n72.42\r\n73.61\r\nAsia\r\n69.23\r\n70.73\r\nEurope\r\n76.70\r\n77.65\r\nOceania\r\n79.74\r\n80.72\r\n\r\nIf you are a visual person like me and wish to see this transformation with explanations, check out this GIF I made using good ol‚Äô PowerPoint.\r\n{tidyr} pivot_wider() explainedConclusion\r\npivot_wider() is the successor for the great spread() function and has many advantages over the latter. This function has many other arguments that allow some truly great transformations. Mastering this function (and its long counterpart) is a great skill upgrade while massaging your data to make it ‚Äútidy‚Äù.\r\nHappy Spreading!\r\nReferences\r\nLong vs.¬†Wide Data: What‚Äôs the Difference?\r\nHadley Wickham and Maximilian Girlich (2022). tidyr: Tidy Messy Data. R package version 1.2.0. https://CRAN.R-project.org/package=tidyr\r\nYihui Xie (2022). knitr: A General-Purpose Package for Dynamic Report Generation in R. R package version 1.39.\r\n\r\n\r\n\r\n",
    "preview": "https://i.imgur.com/A9SfEdJ.gif",
    "last_modified": "2022-09-08T21:49:07+05:30",
    "input_file": {}
  },
  {
    "path": "posts/2022-07-08-tidyrpivotlonger/",
    "title": "Pivoting your tables with Tidyr: Part I",
    "description": "Converting \"wide\" to \"long\" format",
    "author": [
      {
        "name": "Vishal Katti",
        "url": {}
      }
    ],
    "date": "2022-07-08",
    "categories": [
      "Rstats",
      "functions",
      "tidyr",
      "pivot"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nThe wide one\r\nThe long one\r\nConclusion\r\nReferences\r\n\r\nIntro\r\nOne of the primary data manipulation operations is pivoting your tabular data from ‚Äúwide‚Äù format to ‚Äúlong‚Äù format and vice-versa.\r\nThe idea is to make your tabular data ‚Äútidy‚Äù i.e.\r\nEvery column is a variable.\r\nEvery row is an observation.\r\nEvery cell is a single value.\r\nIn other words, every column contains just one type of information, every row in the table is a snapshot or a version of the information your table captures and every cell contains just one piece of information. Read more about wide vs.¬†long formats here.\r\nWhile the wide format is more human-readable, the long format is preferred and is desirable for data and plotting operations using R, Python or other data processing programming languages. The {tidyr} R package has functions that allow you to transform your tabular data between the two formats.\r\nIn this post, we will see how to convert a wide dataframe to long format using the pivot_longer() function from {tidyr} package.\r\nThe wide one\r\nConsider the following data table. It has been created from the famous Gapminder dataset. This table shows the average life expectancy in each continent for 2 years. While some of you may say that Gapminder data contains records for a lot more number of years, here we consider just the latest 2 years for ease of explanation and visual purposes.\r\nContinent-wise Average Life Expectancy over last 2 yearsmy_data is in the wide format as we have continent names in column headers and average life expectancy values in each of those columns. To convert this tibble to the long format, we need to pull together the continent names in one column and their corresponding values into another column.\r\n\r\nThe long one\r\nThe long format of this table would ideally have only year, continent and average_life_expectancy columns and look something like the table below.\r\n\r\nThe long format has repeated values of the column that are not gathered/collected. In this case, the year column gets its values repeated for each row.\r\nLet‚Äôs recreate the above transformation in R. First, we create the my_data table.\r\n\r\n\r\nmy_data <- data.frame(\r\n  year     = c(2002L, 2007L), \r\n  Africa   = c(53.33, 54.81), \r\n  Americas = c(72.42, 73.61), \r\n  Asia     = c(69.23, 70.73), \r\n  Europe   = c(76.70, 77.65), \r\n  Oceania  = c(79.74, 80.72)\r\n)\r\n\r\nknitr::kable(my_data)\r\n\r\nyear\r\nAfrica\r\nAmericas\r\nAsia\r\nEurope\r\nOceania\r\n2002\r\n53.33\r\n72.42\r\n69.23\r\n76.70\r\n79.74\r\n2007\r\n54.81\r\n73.61\r\n70.73\r\n77.65\r\n80.72\r\n\r\nTo convert this table into long format, we use the pivot_longer() function from {tidyr} R package. Let us see how to use this function.\r\nüí°Tip: use formals to view all the formal arguments of a function and their default values. formals returns a named list.\r\n\r\n\r\nlibrary(tidyr, quietly = TRUE, warn.conflicts = FALSE)\r\n\r\nformals(pivot_longer)\r\n\r\n$data\r\n\r\n\r\n$cols\r\n\r\n\r\n$names_to\r\n[1] \"name\"\r\n\r\n$names_prefix\r\nNULL\r\n\r\n$names_sep\r\nNULL\r\n\r\n$names_pattern\r\nNULL\r\n\r\n$names_ptypes\r\nNULL\r\n\r\n$names_transform\r\nNULL\r\n\r\n$names_repair\r\n[1] \"check_unique\"\r\n\r\n$values_to\r\n[1] \"value\"\r\n\r\n$values_drop_na\r\n[1] FALSE\r\n\r\n$values_ptypes\r\nNULL\r\n\r\n$values_transform\r\nNULL\r\n\r\n$...\r\n\r\nThe result of formals(pivot_longer) tells us that the minimum information needed to use this function is to provide values to the data and cols arguments as all other arguments have default values and hence, are optional.\r\nUsing only the minimum arguments with pivot_longer(), we get a long formatted tibble with the columns year, name and value.\r\n\r\n\r\nlong_minimal <- pivot_longer(\r\n                        data      = my_data,\r\n                        cols      = c(\"Africa\", \"Americas\", \"Asia\", \"Europe\", \"Oceania\")\r\n                        )\r\n\r\nknitr::kable(long_minimal)\r\n\r\nyear\r\nname\r\nvalue\r\n2002\r\nAfrica\r\n53.33\r\n2002\r\nAmericas\r\n72.42\r\n2002\r\nAsia\r\n69.23\r\n2002\r\nEurope\r\n76.70\r\n2002\r\nOceania\r\n79.74\r\n2007\r\nAfrica\r\n54.81\r\n2007\r\nAmericas\r\n73.61\r\n2007\r\nAsia\r\n70.73\r\n2007\r\nEurope\r\n77.65\r\n2007\r\nOceania\r\n80.72\r\n\r\nNotice that the continent names and their corresponding average life expectancy values appear in columns named name and value. These are the default column names. We can change these column names by providing our own names to the arguments names_to and values_to.\r\nSince the year column is the only one that remains as is, we can rewrite the above pivot_longer statement as below\r\n\r\n\r\nmy_data_longer <- pivot_longer(data      = my_data,\r\n                               cols      = !year,\r\n                               names_to  = \"continent\",\r\n                               values_to = \"average_life_expectancy\")\r\n\r\nknitr::kable(my_data_longer)\r\n\r\nyear\r\ncontinent\r\naverage_life_expectancy\r\n2002\r\nAfrica\r\n53.33\r\n2002\r\nAmericas\r\n72.42\r\n2002\r\nAsia\r\n69.23\r\n2002\r\nEurope\r\n76.70\r\n2002\r\nOceania\r\n79.74\r\n2007\r\nAfrica\r\n54.81\r\n2007\r\nAmericas\r\n73.61\r\n2007\r\nAsia\r\n70.73\r\n2007\r\nEurope\r\n77.65\r\n2007\r\nOceania\r\n80.72\r\n\r\nIf you are a visual person like me and wish to see this transformation with explanations, check out this GIF I made using good ol‚Äô Powerpoint.\r\n{tidyr} pivot_longer() explainedConclusion\r\npivot_longer() is the successor for the great gather() function and has many advantages over the latter. pivot_longer() repeats all the values in the columns that are not included in the cols argument. Therefore, if your dataframe/tibble had a primary key prior to the transformation, the primary key of your transformed ‚Äúlonger‚Äù dataframe is your old primary key + the new column created by names_to. This function has many other arguments that allow some truly great transformations. Mastering this function (and its wide counterpart) is a great skill upgrade while massaging your data to make it ‚Äútidy‚Äù.\r\nHappy Gathering!\r\nReferences\r\nLong vs.¬†Wide Data: What‚Äôs the Difference?\r\nHadley Wickham and Maximilian Girlich (2022). tidyr: Tidy Messy Data. R package version 1.2.0. https://CRAN.R-project.org/package=tidyr\r\nYihui Xie (2022). knitr: A General-Purpose Package for Dynamic Report Generation in R. R package version 1.39.\r\n\r\n\r\n\r\n",
    "preview": "https://i.imgur.com/0qMbFC1.gif",
    "last_modified": "2022-09-08T21:48:43+05:30",
    "input_file": {}
  },
  {
    "path": "posts/2022-01-18-writingrobustrfunctions/",
    "title": "Writing Robust R Functions",
    "description": "Some designs to validate function arguments.",
    "author": [
      {
        "name": "Vishal Katti",
        "url": {}
      }
    ],
    "date": "2022-01-18",
    "categories": [
      "Rstats",
      "functions"
    ],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nWhat do we mean by Robust Functions?\r\nOur sweet, innocent and naive Function\r\nScenario 1: Missing Arguments\r\n1.1 Early Exit\r\n1.2 Sensible defaults with warnings\r\n\r\nScenario 2: Invalid Argument Data Type\r\nCharacter arguments\r\nFactor arguments\r\n\r\nScenario 3: Incorrect Argument Size\r\nA little detour‚Ä¶\r\nScenario 4: Values of Arguments that result in invalid outputs\r\nConclusion\r\nCitations & References\r\n\r\nIntroduction\r\nFunctions in R ( or any other programming language in general) allow us\r\nto encapsulate some lines of code that we want to run again and again.\r\nFunctions are the natural outcome of the DRY (Don‚Äôt Repeat\r\nYourself!) principle. Functions group together a couple of lines of\r\nconsistent logic making our code modular and consequently, easy to\r\nmanage. However, when we write functions, we need to ensure that they\r\nbehave exactly as we want them to and are able to handle whatever we\r\nthrow at them. By whatever, I mean any and all kinds of inputs. The idea\r\nof creating unbreakable code is idealistic. I say this since creating\r\nrobust functions requires additional code to handle the unwanted inputs\r\nand most useRs write functions during some one-time analysis. Hence we\r\nneed to be pragmatic about how much time and effort we spend trying to\r\nmake our functions robust. Maybe, we need our functions to be just\r\nrobust enough! All I am saying is, if you are creating functions that\r\nwill be used by you and only you i.e.¬†if you have absolute control over\r\nwhat inputs would be provided to your functions, then you can forego\r\ncertain checks and the functions need not be unbreakable. But, if you\r\nintend to write functions that will be used by a larger audience, you\r\nneed to ensure that such functions are able to handle all kinds of\r\ninnocent and malicious intents.\r\nWhat do we mean by Robust Functions?\r\nYou must be familiar with the Garbage-In-Garbage-Out philosophy of\r\nSoftware engineering. We can think of it in terms of functions, that,\r\ngiven garbage or bad input, you get garbage or bad output. For a\r\nfunction to be robust, it must behave in a consistent manner for known\r\nand correct inputs, however, more importantly, it mustn‚Äôt give us\r\ngarbage for bad inputs. Rather, it must provide useful output (as\r\nmessages or instructions) which can be further used to inform the\r\nend-user about possible problems in the inputs to drive proper usage.\r\nThe useful output/s in case of bad inputs would ideally be a combination\r\nof clean early exit and easy-to-understand error messages. So we shall\r\ntry to implement Garbage-In-Useful-Info-Out by looking at some ways we\r\ncan build well-behaved and reliable functions.\r\nInput values passed to a function are more popularly known as arguments\r\nor parameters. A robust function must validate the function arguments\r\nbefore proceeding to implement the function logic. If this is not done,\r\nthen the bad arguments will cause some errors in the logic and display\r\nerror messages that the end-user may not be familiar with. Worst-case\r\nscenario is when the function doesn‚Äôt encounter any errors and just\r\ngives bad results!! Surely, we do not want this unpredictable behavior.\r\nEnough Talk, Let‚Äôs Fight! - Kungfu Panda\r\n@imgflip.comOur sweet, innocent and naive Function\r\nConsider the following function make_date that takes 3 numeric inputs\r\nyyyy, mm and dd and returns a single ‚ÄôDate` object.\r\n\r\n\r\nmake_date <-  function(yyyy, mm, dd) {\r\n  \r\n  # main logic\r\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\r\n}\r\n\r\nmy_date <- make_date(yyyy = 2022, mm = 1, dd = 31)\r\nmy_date\r\n\r\n[1] \"2022-01-31\"\r\n\r\nclass(my_date)\r\n\r\n[1] \"Date\"\r\n\r\nWe will use make_date to demonstrate a couple of scenarios where this\r\nfunction can fail and the methods to safeguard against such scenarios.\r\nScenario 1: Missing Arguments\r\nThe most basic check we should perform before running the function logic\r\nis to confirm if all the required arguments are available. Think about\r\nhow your function should behave if one of the arguments, suppose mm is\r\nmissing.\r\n\r\n\r\nmake_date(yyyy = 2022, dd = 31)\r\n\r\nError in paste(yyyy, mm, dd, sep = \"-\"): argument \"mm\" is missing, with no default\r\n\r\n\r\nNote that the error message shown to the user, is triggered, not from\r\nour function make_date but from the internal paste function. We do\r\nnot have any control over what error messages are shown when errors\r\noccur. In this case, we know specifically that this error is due to a\r\nmissing argument.\r\nThere are two ways to handle missing arguments:\r\n1.1 Early Exit\r\nIf a certain required argument is missing, we can stop the execution of\r\nthe function and show informative error message about which argument is\r\nmissing. Your friends here are the missing and stop functions. The\r\nmissing function checks if the given argument is missing or is set to\r\nNULL and returns TRUE, else it returns FALSE. The stop function stops\r\nthe execution and displays the custom error message we provide. Using\r\nthese functions inside an if condition will let us check for missing\r\narguments. Let us modify our naive function to stop early when required\r\narguments are missing.\r\n\r\n\r\nmake_date <-  function(yyyy, mm, dd) {\r\n  \r\n  # check missing arguments\r\n  if (missing(yyyy)) stop(\"argument `yyyy` is required.\")\r\n  if (missing(mm))   stop(\"argument `mm` is required.\")\r\n  if (missing(dd))   stop(\"argument `dd` is required.\")\r\n  \r\n  # main logic\r\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\r\n}\r\n\r\n# Calling the function without `mm` argument\r\nmake_date(yyyy = 2022, dd = 31)\r\n\r\nError in make_date(yyyy = 2022, dd = 31): argument `mm` is required.\r\n\r\n\r\nNote that here, we add three if-missing-stop statements, one for each\r\nrequired argument. We must do this if we want to display specific error\r\nmessages for each argument. There is another way to do the same but we\r\nwill look at it later. If we want to display a single error message, we\r\ncan do so by clubbing the missing functions inside an any which will\r\nreturn TRUE if any one of the arguments is missing. However, providing\r\nclear error messages becomes challenging in this method.\r\n\r\n\r\ndummy_fun <- function(a, b, c) { \r\n  if(any(missing(a), missing(b), missing(c))) {\r\n    stop(\"One or more required arguments missing.\")\r\n  }\r\n  # Do something...\r\n}\r\ndummy_fun(a = 1)\r\n\r\nError in dummy_fun(a = 1): One or more required arguments missing.\r\n\r\n\r\n1.2 Sensible defaults with warnings\r\nIn some cases, we may need the function to use some sensible default\r\nvalue for the required arguments and continue execution. Here, we\r\ndisplay a warning message instead of an error message. This is required\r\nwhen the argument value is either considered to be obvious or the\r\nargument is not necessarily the most important one and is used only in\r\nextreme customization. Providing default values to arguments makes\r\nthem optional arguments. An example of default argument values can be\r\nseen in the paste function we have used earlier. The default value of\r\nthe separator argument sep is a single whitespace character.\r\n\r\n\r\nargs(paste)\r\n\r\nfunction (..., sep = \" \", collapse = NULL, recycle0 = FALSE) \r\nNULL\r\n\r\nSimilarly, we can provide some sensible defaults for the make_date\r\nfunction. Let‚Äôs modify the function further to provide defaults for the\r\nmm and dd arguments only.\r\n\r\n\r\nmake_date <-  function(yyyy, mm = 1, dd = 1) {\r\n  \r\n  # check missing arguments\r\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \r\n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \r\n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\r\n  \r\n  # main logic\r\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\r\n}\r\n\r\n# Calling the function without `mm` and `dd` arguments\r\nmake_date(yyyy = 2022) # here, only `yyyy` is the required argument.\r\n\r\nWarning in make_date(yyyy = 2022): argument `mm` is missing. Using\r\ndefault value mm = 1 instead\r\n\r\nWarning in make_date(yyyy = 2022): argument `dd` is missing. Using\r\ndefault value dd = 1 instead\r\n\r\n[1] \"2022-01-01\"\r\n\r\nThere are a few concerns about using warnings instead of error messages.\r\nSome are listed here in this article from RBloggers A Warning About\r\nwarning.\r\nScenario 2: Invalid Argument Data Type\r\nWe have defined make_date to accept 3 numeric arguments i.e.¬†all 3\r\nmust be numbers. What would happen if someone tried to call make_date\r\nwith character, factor or boolean inputs?\r\n\r\n\r\nmake_date(yyyy = \"2022\", mm = \"5\", dd = \"20\") # works!! why?\r\n\r\n[1] \"2022-05-20\"\r\n\r\nIn this case, the function works because when the arguments are combined\r\ninto a single string using paste , it matches the format argument of\r\nthe as.Date function in the main logic of make_date which is\r\nas.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\r\n\r\n\r\nmake_date(yyyy = \"2022\", mm = \"May\", dd = \"1\") # works but shows NA !!!\r\n\r\n[1] NA\r\n\r\nIn this case, all the arguments pass the checks but the output is NA\r\nsince we pass 2022-May-1 to as.Date which doesn‚Äôt match the\r\nformat = '%Y-%m-%d'.\r\nHow do we check if the values provided to the arguments are numbers or\r\nnumber-like? If the values are numbers, we let them pass. But if they\r\nare non-numeric, we must check if they can be converted to numbers i.e.\r\nwe must check if they are number-like. By number-like, I mean, will\r\ncoercing the value using as.numeric give us a numeric value or NA ?\r\nYou guessed it right, we will pass the values through as.numeric and\r\ncheck if the output is NA or not.\r\nWhat are the various data types in R that are not numeric but can look\r\nlike numbers? We have character, factor and boolean data types\r\nwhich can behave like numbers sometimes. Let‚Äôs see a few scenarios.\r\nCharacter arguments\r\n\r\n\r\nYear <- c(\"2022\", \"TwentyTwo\")\r\nYear_num <- as.numeric(Year) # this should show a warning about NAs introduced by coercion\r\nYear_num # must show the number 2022 without quotes and one NA\r\n\r\n[1] 2022   NA\r\n\r\nAs you can see in above example, when passed through as.numeric, the\r\nvalue ‚Äú2022‚Äù gets converted to the number 2022 but the value ‚ÄúTwentyTwo‚Äù\r\ndoes not. Hence we can say ‚Äú2022‚Äù is number-like but ‚ÄúTwentyTwo‚Äù is not.\r\nFactor arguments\r\n\r\n\r\nYear <- factor(c(\"2022\",\"2021\",\"TwentyTwo\"))\r\nas.numeric(Year)\r\n\r\n[1] 2 1 3\r\n\r\nYearX <- factor(c(\"2022\", \"X\"))\r\nas.numeric(YearX)\r\n\r\n[1] 1 2\r\n\r\nYearY <- factor(2022)\r\nas.numeric(YearY)\r\n\r\n[1] 1\r\n\r\nAs you can see from above examples, factor values do get converted to\r\nnumeric but do not give the right results. So we can safely say that\r\nfactors are not number-like.\r\nI will ignore boolean data types hoping that useRs are bright enough\r\nto not use Booleans while creating a Date!\r\nFrom the above examples, we can conclude that numeric values and\r\nnumber-like character values are the only valid data types that should\r\nbe allowed. Modifying our make_date function to include data type\r\nchecks.\r\n\r\n\r\nmake_date <-  function(yyyy, mm = 1, dd = 1) {\r\n  \r\n  # check missing arguments\r\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \r\n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \r\n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\r\n  \r\n  # Check data types\r\n  if (!is.numeric(yyyy) & !is.character(yyyy)) {\r\n    stop(\"argument `yyyy` must be numeric\")\r\n  } else if (is.character(yyyy) & is.na(as.numeric(yyyy))) {\r\n    stop(\"argument `yyyy` must be numeric\")\r\n  }\r\n  if (!is.numeric(mm) & !is.character(mm)) {\r\n    stop(\"argument `mm` must be numeric\")\r\n  } else if (is.character(mm) & is.na(as.numeric(mm))) {\r\n    stop(\"argument `mm` must be numeric\")\r\n  }\r\n  if (!is.numeric(dd) & !is.character(dd)) {\r\n    stop(\"argument `dd` must be numeric\")\r\n  } else if (is.character(dd) & is.na(as.numeric(dd))) {\r\n    stop(\"argument `dd` must be numeric\")\r\n  }\r\n  \r\n  # main logic\r\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\r\n}\r\n\r\n# Calling the function with new datatype checks\r\nmake_date(yyyy = \"2022\", mm = \"May\", dd = \"1\")\r\n\r\nError in make_date(yyyy = \"2022\", mm = \"May\", dd = \"1\"): argument `mm` must be numeric\r\n\r\n\r\nmake_date(yyyy = \"2022\", mm = factor(\"5\"), dd = \"1\")\r\n\r\nError in make_date(yyyy = \"2022\", mm = factor(\"5\"), dd = \"1\"): argument `mm` must be numeric\r\n\r\n\r\nNotice that the datatype check is lengthy and similar for all 3\r\narguments. We can apply DRY principle again and encapsulate that\r\ncode into a small function is_numberlike which will return TRUE or\r\nFALSE . Note that is_numberlike has no checks because it is an\r\ninternal function.\r\n\r\n\r\n# This function check if value is number or number-like.\r\nis_numberlike <- function(x){\r\n  if (!is.numeric(x) & !is.character(x)) {\r\n    return(FALSE) # Early Exit 1 if value is neither numeric nor character\r\n  } else if (is.character(x) & is.na(as.numeric(x))) {\r\n    return(FALSE) # Early Exit 2 if character value is not number-like.\r\n  }\r\n  return(TRUE)\r\n}\r\n\r\n\r\nThus our make_date function with data types check will look as below.\r\n\r\n\r\nmake_date <-  function(yyyy, mm = 1, dd = 1) {\r\n  \r\n  # check missing arguments\r\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \r\n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \r\n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\r\n  \r\n  # Check data types\r\n  if (!is_numberlike(yyyy)) stop(\"argument `yyyy` must be numeric\")\r\n  if (!is_numberlike(mm))   stop(\"argument `mm` must be numeric\")\r\n  if (!is_numberlike(dd))   stop(\"argument `dd` must be numeric\")\r\n  \r\n  # main logic\r\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\r\n}\r\n\r\n# Calling the function with new datatype checks\r\nmake_date(yyyy = \"TwentyTwo\", mm = \"5\", dd = 1)\r\n\r\nWarning in is_numberlike(yyyy): NAs introduced by coercion\r\n\r\nError in make_date(yyyy = \"TwentyTwo\", mm = \"5\", dd = 1): argument `yyyy` must be numeric\r\n\r\n\r\nmake_date(yyyy = \"2022\", mm = factor(\"5\"), dd = \"1\")\r\n\r\nError in make_date(yyyy = \"2022\", mm = factor(\"5\"), dd = \"1\"): argument `mm` must be numeric\r\n\r\n\r\nmake_date(yyyy = 2022, mm = 5, dd = \"one\")\r\n\r\nWarning in is_numberlike(dd): NAs introduced by coercion\r\n\r\nError in make_date(yyyy = 2022, mm = 5, dd = \"one\"): argument `dd` must be numeric\r\n\r\n\r\nOne of the most interesting features of R is vectorization! Due to this\r\nfeature, our function make_date behaves in interesting ways. In some\r\ncases, it is desirable and sometimes it is not.\r\n\r\n\r\nmake_date(yyyy = 2022, mm = 1:12, dd = \"1\")\r\n\r\n [1] \"2022-01-01\" \"2022-02-01\" \"2022-03-01\" \"2022-04-01\" \"2022-05-01\"\r\n [6] \"2022-06-01\" \"2022-07-01\" \"2022-08-01\" \"2022-09-01\" \"2022-10-01\"\r\n[11] \"2022-11-01\" \"2022-12-01\"\r\n\r\nNote the above warnings. These warnings appear because the if\r\nstatement checks if the condition provided results in a single TRUE or\r\nFALSE value. However, the output of the check is.na(as.numeric(mm))\r\nis a boolean vector of length 12. But if needs only 1 TRUE or\r\nFALSE.\r\nThe output contains 12 date values since paste is vectorised, it\r\nrecycles the values for yyyy and dd to give us 12 dates!\r\n\r\n\r\nmm <- 1:12\r\npaste(\"Month\", mm)\r\n\r\n [1] \"Month 1\"  \"Month 2\"  \"Month 3\"  \"Month 4\"  \"Month 5\"  \"Month 6\" \r\n [7] \"Month 7\"  \"Month 8\"  \"Month 9\"  \"Month 10\" \"Month 11\" \"Month 12\"\r\n\r\nWhat do we do if we want make_date to return just one date?\r\nScenario 3: Incorrect Argument Size\r\nTo ensure make_date gives you just one date, we must ensure that the\r\narguments have just value and is not a vector of multiple values i.e.\r\nlength(arg)==1. Let‚Äôs further add a few checks for the data size of\r\nthe arguments and rearrange the checks.\r\n\r\n\r\nmake_date <-  function(yyyy, mm = 1, dd = 1) {\r\n  \r\n  # check missing arguments\r\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \r\n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \r\n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\r\n  \r\n  # Check argument lengths\r\n  if (length(yyyy)!=1) stop(paste0(\"Length of argument `yyyy` is \", length(yyyy),\". Must be only 1.\"))\r\n  if (length(mm)!=1)   stop(paste0(\"Length of argument `mm` is \", length(mm),\". Must be only 1.\"))\r\n  if (length(dd)!=1)   stop(paste0(\"Length of argument `dd` is \", length(dd),\". Must be only 1.\"))\r\n  \r\n  # Check data types\r\n  if (!is_numberlike(yyyy)) stop(\"argument `yyyy` must be numeric\")\r\n  if (!is_numberlike(mm))   stop(\"argument `mm` must be numeric\")\r\n  if (!is_numberlike(dd))   stop(\"argument `dd` must be numeric\")\r\n  \r\n  # main logic\r\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\r\n}\r\n\r\n# Calling function with new data size checks\r\nmake_date(yyyy = 2022, mm = 1:12, dd = \"01\")\r\n\r\nError in make_date(yyyy = 2022, mm = 1:12, dd = \"01\"): Length of argument `mm` is 12. Must be only 1.\r\n\r\n\r\nmake_date(yyyy = c(\"2021\",\"2022\"), mm = \"1\", dd = 1)\r\n\r\nError in make_date(yyyy = c(\"2021\", \"2022\"), mm = \"1\", dd = 1): Length of argument `yyyy` is 2. Must be only 1.\r\n\r\n\r\nmake_date(yyyy = 2022, mm = 1, dd = c(\"1\",\"2\"))\r\n\r\nError in make_date(yyyy = 2022, mm = 1, dd = c(\"1\", \"2\")): Length of argument `dd` is 2. Must be only 1.\r\n\r\n\r\nA little detour‚Ä¶\r\nSo far we checked for missing arguments, arguments with bad data types\r\nand arguments with incorrect sizes. We‚Äôve used the stop function along\r\nwith if to check for all failure conditions and show appropriate error\r\nmessages. When we use stop, we must specify all the failure conditions\r\nand the number of specific error messages goes up as number of arguments\r\nincreases.\r\nIn case of our make_date, if an argument is not missing, it must be a\r\nnumber-like value of length 1. To reduce the number of error messages,\r\nwe can combine the error messages for data type and length. for eg, the\r\nerror message could be argument yyyy must be a number-like value of\r\nlength 1.\r\nWouldn‚Äôt it be easier if we just specify what is the success condition\r\naka the ‚Äúhappy path‚Äù, and show error for all other conditions? To do\r\nthis, we can use the stopifnot function that let‚Äôs us specify all the\r\nhappy paths. See example below.\r\n\r\n\r\ndummy_sum <- function(a, b, c){\r\n  \r\n  # check missing\r\n  stopifnot(!missing(a) & !missing(b) & !missing(c))\r\n  \r\n  # check argument values\r\n  stopifnot(!is.na(a) & is.numeric(a) & length(a)==1,\r\n            !is.na(b) & is.numeric(b) & length(b)==1,\r\n            !is.na(c) & is.numeric(c) & length(c)==1\r\n            )\r\n  sum(a, b, c)\r\n}\r\n\r\ndummy_sum(b = 2, c = 3) # a is missing\r\n\r\nError in dummy_sum(b = 2, c = 3): !missing(a) & !missing(b) & !missing(c) is not TRUE\r\n\r\n\r\ndummy_sum(a = NA_integer_, b = 2, c = 3) # a has NA value\r\n\r\nError in dummy_sum(a = NA_integer_, b = 2, c = 3): !is.na(a) & is.numeric(a) & length(a) == 1 is not TRUE\r\n\r\n\r\ndummy_sum(a = 1, b = \"2\", c = 3) # b has non-numeric value\r\n\r\nError in dummy_sum(a = 1, b = \"2\", c = 3): !is.na(b) & is.numeric(b) & length(b) == 1 is not TRUE\r\n\r\n\r\ndummy_sum(a = 1, b = 2, c = 5:7)  # c has length != 1\r\n\r\nError in dummy_sum(a = 1, b = 2, c = 5:7): !is.na(c) & is.numeric(c) & length(c) == 1 are not all TRUE\r\n\r\n\r\nNote the error messages above. They are not so user-friendly. Luckily,\r\nwe can specify error messages in stopifnot by providing the error\r\nmessages as the names of the ‚Äúhappy path‚Äù conditions.\r\n\r\n\r\ndummy_sum <- function(a, b, c){\r\n  \r\n  # check missing\r\n  stopifnot(\"one or more required arguments missing\" = !missing(a) & !missing(b) & !missing(c))\r\n  \r\n  # check argument values\r\n  stopifnot(\"argument `a` must not be NA, must be a number of length 1\" = !is.na(a) & is.numeric(a) & length(a)==1,\r\n            \"argument `b` must not be NA, must be a number of length 1\" = !is.na(b) & is.numeric(b) & length(b)==1,\r\n            \"argument `c` must not be NA, must be a number of length 1\" = !is.na(c) & is.numeric(c) & length(c)==1\r\n            )\r\n  sum(a, b, c)\r\n}\r\n\r\ndummy_sum(b = 2, c = 3) # a is missing\r\n\r\nError in dummy_sum(b = 2, c = 3): one or more required arguments missing\r\n\r\n\r\ndummy_sum(a = NA_integer_, b = 2, c = 3) # a has NA value\r\n\r\nError in dummy_sum(a = NA_integer_, b = 2, c = 3): argument `a` must not be NA, must be a number of length 1\r\n\r\n\r\ndummy_sum(a = 1, b = \"2\", c = 3) # b has non-numeric value\r\n\r\nError in dummy_sum(a = 1, b = \"2\", c = 3): argument `b` must not be NA, must be a number of length 1\r\n\r\n\r\ndummy_sum(a = 1, b = 2, c = 5:7)  # c has length != 1\r\n\r\nError in dummy_sum(a = 1, b = 2, c = 5:7): argument `c` must not be NA, must be a number of length 1\r\n\r\n\r\nUsing stopifnot in our make_date function to combine the datatype\r\nand length checks, we get‚Ä¶\r\n\r\n\r\nmake_date <-  function(yyyy, mm = 1, dd = 1) {\r\n  \r\n  # check missing arguments\r\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \r\n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \r\n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\r\n  \r\n  \r\n  # Check argument types and length\r\n  stopifnot(\r\n    \"argument `yyyy` must be numeric with length 1\" = is_numberlike(yyyy) & length(yyyy)==1,\r\n    \"argument `mm` must be numeric with length 1\"   = is_numberlike(mm)   & length(mm)==1,\r\n    \"argument `dd` must be numeric with length 1\"   = is_numberlike(dd)   & length(dd)==1\r\n  )\r\n  \r\n  # main logic\r\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\r\n}\r\n\r\nmake_date() # no arguments provided\r\n\r\nError in make_date(): argument `yyyy` is required.\r\n\r\n\r\nmake_date(yyyy = 2022, mm = 1:12, dd = 31) # Length mm not equal to 1\r\n\r\nWarning in if (is.character(x) & is.na(as.numeric(x))) {: the\r\ncondition has length > 1 and only the first element will be used\r\n\r\nError in make_date(yyyy = 2022, mm = 1:12, dd = 31): argument `mm` must be numeric with length 1\r\n\r\n\r\nmake_date(yyyy = 2022, mm = \"Jan\", dd = 31) # mm is not number-like\r\n\r\nWarning in is_numberlike(mm): NAs introduced by coercion\r\n\r\nError in make_date(yyyy = 2022, mm = \"Jan\", dd = 31): argument `mm` must be numeric with length 1\r\n\r\n\r\nmake_date(yyyy = 2022, dd = 31) # argument mm is missing but should work using default value\r\n\r\nWarning in make_date(yyyy = 2022, dd = 31): argument `mm` is missing.\r\nUsing default value mm = 1 instead\r\n\r\n[1] \"2022-01-31\"\r\n\r\nScenario 4: Values of Arguments that result in invalid outputs\r\nFinally, what do we do when the arguments provided will definitely give\r\nus bad results despite passing all checks? In our case, make_date\r\ncreates a date but if we give it values that will result in an invalid\r\ndate, it will give us invalid results (remember\r\nGarbage-In-Garbage-Out?).\r\n\r\n\r\nmake_date(yyyy = 2022, mm = 13, dd = 1) # is there a 13th month?\r\n\r\n[1] NA\r\n\r\nWe get NA because as.Date returns NA for invalid inputs with no\r\nerror messages or warnings! We can check the output and provide a\r\ngeneric error message.\r\n\r\n\r\nmake_date <-  function(yyyy, mm = 1, dd = 1) {\r\n  # check missing arguments\r\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \r\n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \r\n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\r\n  \r\n  \r\n  # Check argument types and length\r\n  stopifnot(\r\n    \"argument `yyyy` must be numeric with length 1\" = is_numberlike(yyyy) & length(yyyy)==1,\r\n    \"argument `mm` must be numeric with length 1\"   = is_numberlike(mm)   & length(mm)==1,\r\n    \"argument `dd` must be numeric with length 1\"   = is_numberlike(dd)   & length(dd)==1\r\n  )\r\n  \r\n  # main logic\r\n  out <- as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\r\n  if (is.na(out)) {\r\n    stop(\"Invalid values provided. Please check your inputs.\")\r\n  }\r\n  return(out)\r\n}\r\n\r\nmake_date(yyyy = 2022, mm = 13, dd = 1) # is there a 13th month?\r\n\r\nError in make_date(yyyy = 2022, mm = 13, dd = 1): Invalid values provided. Please check your inputs.\r\n\r\n\r\nmake_date(yyyy = 2022, mm = 2, dd = 31) # are there 31 days in February?\r\n\r\nError in make_date(yyyy = 2022, mm = 2, dd = 31): Invalid values provided. Please check your inputs.\r\n\r\n\r\nDo you think our function make_date is robust enough?\r\nAs robust as Superman! Source:\r\nImgurConclusion\r\nMaking functions robust requires some prior thought about its intended\r\nuse and audience. Based on this, we can decide what checks to implement,\r\nwhat to skip, whether to stop execution using error messages or to use\r\ndefault values with warnings. Checking for ‚Äúhappy paths‚Äù is simpler\r\ncompared to checking each and every bad input and providing specific\r\nerror messages. Too many different error messages for the same argument\r\ncould become a source of frustration of the end user, so consider\r\ncombining some checks and their error messages to be informative and\r\nprecise. Robustness, like everything else, in moderation, is good and\r\ngetting it ‚Äújust right‚Äù takes time and dedicated effort. Happy Coding!\r\nCitations & References\r\nTechniques for writing robust R programs -\r\nLexJansen\r\nR Programming for Data\r\nScience\r\nA Warning About\r\nwarning\r\n\r\n\r\n\r\n",
    "preview": "https://i.imgur.com/hbjbLMN.gif",
    "last_modified": "2022-09-08T21:47:32+05:30",
    "input_file": {}
  },
  {
    "path": "posts/2021-12-29-rtovbatoppt/",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 2 of 2",
    "description": "Using R to trigger Excel VBA macros to create PowerPoint presentations",
    "author": [
      {
        "name": "Vishal Katti",
        "url": {}
      }
    ],
    "date": "2021-12-29",
    "categories": [
      "Rstats",
      "Excel",
      "VBA",
      "PowerPoint",
      "openxlsx",
      "RDCOMClient"
    ],
    "contents": "\r\n\r\nContents\r\nQuick Recap\r\nStrategy\r\nCreating the datasets\r\nSlide 1\r\nSlide 2\r\nSlide 3\r\n\r\nThe for loop!\r\nReferences & Citations\r\n\r\nThis is part 2 of 2. Read part 1\r\nhere.\r\nQuick Recap\r\nIn the previous post, we create the .potx template from the .pptx\r\nfile we wanted to automate and the Excel template with the macro .xlsm\r\nthat uses the PowerPoint template to create a new .pptx file with\r\ngiven data using VBA.\r\nThe report we want to automate is‚Ä¶\r\nThe Gapminder Report : The PowerPoint presentation we want to\r\nautomate‚Ä¶and the Excel and PowerPoint template we created are shown below.\r\nExcel Template with VBA\r\nmacroIn this post, we will write the R script that will first massage the\r\ndata into desired format and then load the data for one region into the\r\nExcel template and execute the VBA macro that will create the PowerPoint\r\nfile with that data.\r\nStrategy\r\nBefore we dive into code, we need to check a few things. We wish to\r\ncreate a presentation for each continent in the Gapminder data. A closer\r\nlook at the Presentation will tell you what kind of data we need for\r\neach slide/graph/table while the Excel template will reveal what should\r\nthe structure of each dataset should be. While looking into this\r\nstructure, some questions will pop-up. The idea here is to create the\r\ndatasets in such a way that they can be easily filtered for each\r\ncontinent and the resultant table can be written to the Excel template\r\nwithout any or very little modification. Let us proceed slide-by-slide.\r\nCreating the datasets\r\nSlide 1\r\nSlide 1 is the title page and needs 2 strings; one for Title, one for\r\nSubtitle. The Title for the base presentation is ‚ÄúWorld Population‚Äù. For\r\neach continent, it could be ‚Äú<continent_name> Population‚Äù. The\r\nsubtitle is a combination of Author Name and Created Date. So we need a\r\nstring like ‚Äú<author_name> | <created_date>‚Äù where created_date is\r\nthe formatted system date.\r\nThese strings can be created while writing the data to the Excel\r\ntemplate.\r\nSlide 2\r\nThe chart on slide 2 needs raw data structured as below. You will notice\r\nthat at a continent-level, this table needs a minimum of 5 countries. Do\r\nwe have any continents in the Gapminder data with less than 5 countries?\r\nYes, we have Oceania with only Australia and New Zealand. For ease of\r\nuse, let us include these countries along with Asian countries in a new\r\nRegion variable.\r\n02_chartWe will create the region variable in the gapminder data. But first,\r\nlet us load some relevant packages.\r\n\r\n\r\noptions(tidyverse.quiet = TRUE)\r\nlibrary(tidyverse) # duh!\r\nlibrary(reactable) # to display the tables interactively in this post. Not really needed for the final solution.\r\nlibrary(openxlsx) # to write the data to the Excel Template.\r\n# library(RDCOMClient) # to load and run the Excel macro post data load.\r\n\r\n\r\n\r\n\r\n# Read in Gapminder data\r\ngp <- gapminder::gapminder\r\n\r\n# Create new region variable\r\ngp <- gp %>%\r\n  mutate(region = if_else(as.character(continent) %in% c(\"Asia\",\"Oceania\"),\r\n                          \"Asia-Pacific\", \r\n                          as.character(continent)),\r\n         country = as.character(country))\r\n\r\n# Keep only relevant columns\r\ngp <- gp %>% select(region, country, year, pop)\r\n\r\n# View details\r\nglimpse(gp)\r\n\r\nRows: 1,704\r\nColumns: 4\r\n$ region  <chr> \"Asia-Pacific\", \"Asia-Pacific\", \"Asia-Pacific\", \"Asi~\r\n$ country <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghan~\r\n$ year    <int> 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992~\r\n$ pop     <int> 8425333, 9240934, 10267083, 11537966, 13079460, 1488~\r\n\r\nNow that we have the source data available, we must now create the\r\ndatasets we need that we can write to the Excel template for each\r\nregion.\r\nThe required table shows the top 4 countries (based on 2007 population)\r\nand all other countries clubbed into ‚Äòothers‚Äô in a given region and then\r\nthe total population of the region on a yearly basis. This table has to\r\nbe created for all 4 regions.\r\n\r\n\r\npop_trend <- gp %>%\r\n  group_by(region, country, year) %>% \r\n  summarise(pop = sum(pop, na.rm = TRUE),\r\n            .groups = 'drop') %>%\r\n  mutate(pop = round(pop/1E6, 0)) %>% # population in millions\r\n  pivot_wider(names_from = year, values_from = pop, names_sort = TRUE) %>% \r\n  arrange(desc(`2007`)) # sort by max pop to min pop in latest year i.e. 2007\r\n\r\nreactable(pop_trend, compact=TRUE,\r\n                     style = \"font-size:12px\")\r\n\r\n\r\n\r\nNow that we have the required columns, let‚Äôs plan the row order. We\r\nnotice that, for each region, we have the top 4 countries (as per 2007)\r\n, followed by ‚ÄòOthers‚Äô. Let‚Äôs create the top-4 dataset.\r\n\r\n\r\ntop4 <- pop_trend %>% \r\n  group_by(region) %>% \r\n  slice_max(`2007`, n = 4, with_ties = FALSE) %>% \r\n  ungroup()\r\n\r\nreactable(top4, compact=TRUE, style = \"font-size:12px\")\r\n\r\n\r\n\r\nTo create the others dataset, we exclude all countries that are\r\npresent in the top-4.\r\n\r\n\r\nothers <- pop_trend %>% \r\n  filter(!country %in% top4$country) %>% \r\n  group_by(region) %>% \r\n  summarise(across(.cols = -country, .fns = sum),\r\n            .groups = 'drop') %>% \r\n  mutate(country = \"Others\") %>% \r\n  select(region, country, everything())\r\n\r\nreactable(others, compact=TRUE, style = \"font-size:12px\")\r\n\r\n\r\n\r\nWhile we create the top-4 and others datasets separately, we will\r\ncombine them later at the very last moment before writing them to the\r\nExcel template.\r\nNow that we have the datasets needed for 02_chart, let‚Äôs proceed to\r\nthe create 02_table . This table gives you the count of countries that\r\nfall under various population ranges.\r\n02_table on Slide 2Let‚Äôs create 02_table. To create this table, we first create a new\r\nvariable called pop_range.\r\n\r\n\r\npop_levels <- c('Less than 500K','500K - 1 Million',\r\n                '1M - 10 Million', '10M - 100 Million',\r\n                '100M - 1 Billion', 'More than 1 Billion')\r\n\r\ngp2007 <- gp %>% \r\n  filter(year == 2007) %>% \r\n  mutate(pop_range = case_when(pop < 5E5 ~ pop_levels[1],\r\n                               pop < 1E6 ~ pop_levels[2],\r\n                               pop < 1E7 ~ pop_levels[3],\r\n                               pop < 1E8 ~ pop_levels[4],\r\n                               pop < 1E9 ~ pop_levels[5],\r\n                               TRUE      ~ pop_levels[6]),\r\n         pop_range = factor(pop_range, levels = pop_levels))\r\n\r\npop_groups <- gp2007 %>% \r\n  group_by(region, pop_range, .drop = FALSE) %>% \r\n  summarise(`# of Countries` = n(),\r\n            .groups = 'drop') %>% \r\n  arrange(region, pop_range) %>% \r\n  rename(`Population Category` = pop_range)\r\n\r\nreactable(pop_groups, compact=TRUE, style = \"font-size:12px\")\r\n\r\n\r\n\r\nSlide 3\r\nSlide 3 contains 2 strings and one chart. The data for the chart looks\r\nas shown below.\r\n03_chart table for Slide 3The data for 03_chart is the list of top 10 countries in each region\r\nas per latest record i.e.¬†2007. Let‚Äôs create the top10 table.\r\n\r\n\r\ntop10 <- gp %>% \r\n  filter(year == 2007) %>% \r\n  group_by(region) %>% \r\n  slice_max(pop, n = 10, with_ties = FALSE) %>% \r\n  ungroup() %>% \r\n  select(-year) %>% \r\n  mutate(pop = round(pop/1E6, 4)) %>% # population in millions\r\n  set_names(c(\"region\",\"country\",\"population\"))\r\n\r\nreactable(top10, compact=TRUE, style = \"font-size:12px\")\r\n\r\n\r\n\r\nThe for loop!\r\nWe now have to load the Excel template with the data at appropriate cell\r\nlocations for one region at a time. Since we have about 4 regions, we\r\nwill create a vector of unique regions to iterate over.\r\n\r\n\r\nunique_regions <- gp %>% distinct(region) %>% pull()\r\ncat(unique_regions, sep = \"\\n\")\r\n\r\nAsia-Pacific\r\nEurope\r\nAfrica\r\nAmericas\r\n\r\nAs our last step, we will create the for loop that will iterate over\r\nunique_regions , filter the datasets for each region, write them to\r\nthe Excel Template, save the template with temporary name. We save the\r\nfile with different name to prevent unintentionally corrupting the Excel\r\nmacro template. Finally, we run the macro in the renamed file.\r\nThe code will look something like this\r\n\r\n\r\nfor (region in unique_regions) {\r\n  \r\n  # Step 1: filter the data sets\r\n  # Step 2: write the data sets\r\n  # Step 3: save the excel template with different name\r\n  # Step 4: load the renamed Excel file\r\n  # Step 5: run macro\r\n}\r\n\r\n\r\nLet‚Äôs populate the above for loop with the code we need.\r\n\r\n\r\nfor (curr_region in unique_regions) {\r\n  \r\n  # Step 1: filter the data sets\r\n  \r\n  # Slide 1\r\n  S1_title <- paste(curr_region, \"Population\")\r\n  S1_subtitle <- paste(\"Vishal Katti\",\"|\",format(Sys.Date(),\"%b %d, %Y\"), sep = \"   \")\r\n  \r\n  # Slide 2\r\n  S2_title <- paste(curr_region, \"Population since 1952\")\r\n  \r\n  S2_top4 <- top4        %>% filter(region == all_of(curr_region)) %>% select(-region) %>% arrange(desc(`2007`))\r\n  S2_others <- others    %>% filter(region == all_of(curr_region)) %>% select(-region)\r\n  S2_top5 <- bind_rows(S2_top4, S2_others)\r\n  \r\n  S2_table <- pop_groups %>% filter(region == all_of(curr_region)) %>% select(-region)\r\n  \r\n  # Slide 3\r\n  S3_title <- paste(\"Top 10 most populated countries in\", curr_region)\r\n  \r\n  S3_chart <- top10      %>% filter(region == all_of(curr_region)) %>% select(-region)\r\n  \r\n  S3_factoid <- paste(\"The population of\", S3_chart$country[1], \"is approx.\",\r\n                      round(S3_chart$population[1]/S3_chart$population[10], 0),\r\n                      \"times that of\", S3_chart$country[10])\r\n  \r\n  # Step 2: write the data sets\r\n  \r\n  # Load the template\r\n  wb <- loadWorkbook(\"path/to/template/XL2PPT.xlsm\") # relative to this R script\r\n  sht <- \"Sheet1\"\r\n  \r\n  # write data to coordinate (col, row)\r\n  writeData(wb, sht, S1_title,    xy = c(3, 3),  colNames = FALSE)\r\n  writeData(wb, sht, S1_subtitle, xy = c(3, 4),  colNames = FALSE)\r\n  writeData(wb, sht, S2_title,    xy = c(3, 7),  colNames = FALSE)\r\n  writeData(wb, sht, S2_top5,     xy = c(3, 9),  colNames = TRUE)\r\n  writeData(wb, sht, S2_table,    xy = c(18, 9), colNames = TRUE)\r\n  writeData(wb, sht, S3_title,    xy = c(3, 18), colNames = FALSE)\r\n  writeData(wb, sht, S3_factoid,  xy = c(3, 19), colNames = FALSE)\r\n  writeData(wb, sht, S3_chart,    xy = c(3, 21), colNames = TRUE)\r\n  \r\n  # Step 3: save the excel template with different name\r\n  saveWorkbook(wb, \"path/to/template/XL2PPT_edited.xlsm\", overwrite = TRUE)\r\n  gc(verbose = TRUE)\r\n  Sys.sleep(2)\r\n  \r\n  # Step 4: load the renamed Excel file\r\n  # Create Excel Application\r\n  xlApp <- COMCreate(\"Excel.Application\")\r\n\r\n  # Open the Macro Excel book\r\n  xlWbk <- xlApp$Workbooks()$Open(normalizePath(\"path/to/template/XL2PPT_edited.xlsm\", winslash = \"/\")) # Change to your directory\r\n  # its ok to run macro without visible excel application\r\n  # If you want to see your workbook, please set it to TRUE\r\n  xlApp[[\"Visible\"]] <- FALSE\r\n  \r\n  # Step 5: run macro\r\n  xlApp$Run(\"Create_Continental_Deck\") # Name of Macro to run\r\n\r\n  xlWbk$Close(TRUE) # save and close excel book\r\n  xlApp$Quit()\r\n  gc(verbose = TRUE)\r\n  Sys.sleep(2)\r\n}\r\n\r\n\r\nOnce the code runs completely, you will see 4 new PowerPoint\r\nPresentations in your working folder.\r\nOutput FilesYou can download the full R script from\r\nhere.\r\nReferences & Citations\r\nJennifer Bryan (2017). gapminder: Data from Gapminder. R package\r\nversion 0.3.0. https://CRAN.R-project.org/package=gapminder\r\nHadley Wickham, Romain Francois, Lionel Henry and Kirill Muller\r\n(2021). dplyr: A Grammar of Data Manipulation. R package version\r\n1.0.7. https://CRAN.R-project.org/package=dplyr\r\nHadley Wickham (2021). tidyr: Tidy Messy Data. R package version\r\n1.1.3. https://CRAN.R-project.org/package=tidyr\r\nGreg Lin (2020). reactable: Interactive Data Tables Based on ‚ÄòReact\r\nTable‚Äô. R package version 0.2.3.\r\nhttps://CRAN.R-project.org/package=reactable\r\nPhilipp Schauberger and Alexander Walker (2021). openxlsx: Read,\r\nWrite and Edit xlsx Files. R package version 4.2.4.\r\nhttps://CRAN.R-project.org/package=openxlsx\r\nDuncan Temple Lang (NA). RDCOMClient: R-DCOM client.\r\nhttp://www.omegahat.net/RDCOMClient, http://www.omegahat.net\r\nhttp://www.omegahat.net/bugs.\r\nhttps://docs.microsoft.com/en-us/office/vba/api/overview/excel\r\nhttps://docs.microsoft.com/en-us/office/vba/api/overview/powerpoint\r\n\r\n\r\n\r\n",
    "preview": "https://i.imgur.com/T6uCTXN.png",
    "last_modified": "2022-09-08T21:47:02+05:30",
    "input_file": {}
  },
  {
    "path": "posts/2021-08-29-rtovbatoppt/",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 1 of 2",
    "description": "Using R to trigger Excel VBA macros to create PowerPoint presentations!",
    "author": [
      {
        "name": "Vishal Katti",
        "url": {}
      }
    ],
    "date": "2021-10-19",
    "categories": [
      "Rstats",
      "Excel",
      "VBA",
      "PowerPoint"
    ],
    "contents": "\r\n\r\nContents\r\nTL;DR\r\nThe PowerPoint Template\r\nThe Excel Template\r\nThe VBA Macro\r\nR\r\n\r\nOne of the most common tasks in most offices, is creating presentations\r\nand reports in Microsoft PowerPoint. While the tool is great for\r\ncreating ad hoc presentations, editing the same with new data on a\r\nperiodic basis gets tedious. Now, I know that some wonderful packages\r\nlike officer and officedown exist that enable us to create\r\nPowerPoint presentations with editable charts from R itself. You can\r\nread all about this in the amazing Alison Hill‚Äôs blog post ‚ÄúUp and\r\nrunning with\r\nofficedown‚Äù.\r\nSince I discovered R while looking for a better alternative to VBA for\r\ndata analysis and Excel/PowerPoint automation, the following is an\r\nalternative workflow to create multiple PowerPoint presentations using a\r\ncombination of these technologies. Note that this workflow uses the\r\nRDCOMClient package which works in Windows environment only.\r\nTL;DR\r\nIn this 2-part blog, we create a PowerPoint template with named\r\nplaceholders which we populate from an Excel file using VBA. The Excel\r\nfile is loaded with data using R with the help of openxlsx package and\r\nthen the macro is triggered using the RDCOMClient package.\r\nThis solution has great potential to give you the same feeling as those\r\nJurassic Park scientists that Dr.¬†Ian Malcolm remarked about!\r\nAdvantages of this approach over officer and officedown:\r\nSlide/content/header/footer formatting control is in the PowerPoint\r\ntemplate rather than R code.\r\nAll charts are native and can contain any feature (dual axis, mixed\r\ndata series like bar + line, line + points). All Excel chart-types\r\nare available. Go wild!\r\nYou can use any PowerPoint template design (Yes, even your\r\nsad/weird/exciting corporate template!).\r\nLet‚Äôs begin.\r\nSuppose we want to automate the following PowerPoint presentation. It\r\ncontains 3 slides with a title slide and 2 content slides having graphs\r\nand tables created from the gapminder dataset. This .pptx file also\r\nhas a custom footer.\r\nThe Gapminder World Population\r\nReportWe want to create the same presentation with same structure but at a\r\ncontinent-level. gapminder has data for 5 continents and we wish to\r\ncreate 5 presentations by the end of this.\r\nThe PowerPoint Template\r\nIn this approach, we start with the PowerPoint presentation file. We\r\nwill create a template with placeholders and charts with dummy data.\r\nUsually, you would have a copy of the .pptx file you want to automate.\r\nSave a copy of it as a PowerPoint Template (.potx), ideally to your R\r\nProject folder. To know more about what an R Project is, read about it\r\nhere.\r\nIn my case, I‚Äôve created a new R Project folder named R2XL2PPT as\r\nshown below.\r\nSave As PowerPoint Template\r\n(.potx)Now let us prep the template. If you open the template file by\r\ndouble-click or right-click > New, it would open a fresh .pptx\r\npresentation using the template. Right-Click and click Open in the\r\ncontext menu to open the .potx template file for editing.\r\nCORRECT: Right-Click > OpenOnce you have the template open, we will add names to all the text\r\nplaceholders, tables and graphs we wish to update. To update the\r\nplaceholder name:\r\nSelect the shape/text-area/table/graph.\r\nFrom Shape Format, click Selection Pane.\r\nIn the Selection Pane, change the name of the selected item.\r\nAdd shape names from Selection\r\nPaneAdvisory: We use the format NN_[Position]Object where NN is the\r\nslide number, [Position] is the either TopLeft, TopRight, BottomLeft,\r\nBottomRight or any other position and finally, Object is either Table,\r\nChart, Title, Subtitle, TextBox etc. You can use any fancy identifier\r\nhere, just make sure that your future self and others can recognise them\r\neasily.\r\nOnce you set the names of all the items that you want to customise, save\r\nthe template.\r\nDownload the GP_template.potx template\r\nhere.\r\nThe Excel Template\r\nTo populate all the named items in the PowerPoint template, we will now\r\ncreate an Excel document which looks identical to the template with\r\nrespect to the named items. Please see image below.\r\nPowerPoint item to Excel named range\r\nmappingFor every named item, depending on whether it is a textbox or chart or\r\ntable, we will create a named range for that item. For example, for item\r\n01_title in the PowerPoint template, we create a S1_title named\r\nrange (which points to cell C3) as a placeholder for it. If you don‚Äôt\r\nknow how to create a named range in Excel, read more\r\nhere.\r\n\r\nExcel does not allow named ranges names to start with a number, hence\r\n01_title is mapped to S1_title. The S stands for Slide. Just one\r\nof those Excel quirks I guess!\r\n\r\nYou can set a single Excel cell as named range for each textbox in\r\nthe PowerPoint template. You can copy-paste tables from Powerpoint\r\nto the Excel template directly. The entire table must be set as a named\r\nrange.\r\nFor charts, right-click the chart in PowerPoint and select Edit Data.\r\nAn excel worksheet is displayed with the underlying data. Copy-paste the\r\nentire data into the Excel template.\r\nExcel Chart: Right Click > Edit\r\nDataFor the GP_template.potx, the corresponding excel template\r\nXL2PPT.xlsm looks like the below image. Please note that this template\r\ndoes not have the VBA macro yet.\r\nXL2PPT designThe VBA Macro\r\nWe want the VBA macro to:\r\nOpen a new instance of PowerPoint presentation using the\r\nGP_template.potx file.\r\nCopy text/numbers from various placeholders and replace existing\r\ntext/numbers in the PowerPoint presentation.\r\nSave the presentation with custom file name with .pptx extension.\r\nThe actual mapping of the named ranges in the Excel template to the\r\nnamed shapes in the PowerPoint template happens in the VBA code.\r\nHowever, at this stage, you can actually create the PowerPoint\r\npresentation by copying the numbers into the Excel template and hitting\r\nthe big RUN MACRO button.\r\nFor your reference, I am embedding the VBA macro code below. You can\r\ndownload the XL2PPT.xlsm file from here.\r\n\r\n VBA Macro Code \r\n\r\n\r\nR\r\nSuppose we want to create a 10 variations of PowerPoint presentation\r\nusing the same template. While creating the presentation from Excel is\r\nnow automated, how about creating the numbers for each of those 10\r\nvariations? This is where we bring in R with the openxlsx and\r\nRDCOMClient packages. We use the tidyverse set of packages to read\r\nin data, clean and massage the data into the various formats we need,\r\nopenxlsx to write the data (single numbers, text or tables of numbers)\r\nto the Excel template and RDCOMClient to run the embedded VBA code in\r\nthe Excel template.\r\nCheck out the upcoming Part 2 of this blog to see how to run VBA code\r\nusing R. Let me know if you find this useful or any corrections required\r\nin the comments below.\r\n\r\n\r\n\r\n",
    "preview": "https://i.imgur.com/T6uCTXN.png",
    "last_modified": "2022-09-08T21:46:25+05:30",
    "input_file": {}
  },
  {
    "path": "posts/2021-07-27-drilldown/",
    "title": "Interactive Drill-down Tables using {reactable}",
    "description": "How to create multi-level tables with hidden rows",
    "author": [
      {
        "name": "Vishal Katti",
        "url": {}
      }
    ],
    "date": "2021-07-27",
    "categories": [
      "Rstats",
      "reactable",
      "drill-down"
    ],
    "contents": "\r\n\r\nContents\r\nTop-Level data: course\r\nSecond Level Data: student\r\nVanilla reactable\r\nBasic Formatting\r\nGrouping and Aggregating\r\nThe final Drill-down Table\r\nConclusion\r\nReferences & Citations\r\n\r\nWe often come across denormalized data that has 2 or more levels of information. For example, top-level info like course info with data fields like course id, course name, description, start/end date and second-level info like student info with data fields like with student id, student name, age and gender. We may also have these two groups of data as separate tables with a primary-key foreign-key design, usually from a well-designed SQL database.\r\n\r\nNOTE: If you are reading this article from anywhere except https://vishalkatti.com, you may not see some of the interactive elements below. Go to original post here\r\n\r\nLet us create some data.\r\nTop-Level data: course\r\n\r\n\r\nlibrary(dplyr, quietly = TRUE, warn.conflicts = FALSE)\r\nlibrary(rmarkdown, quietly = TRUE, warn.conflicts = FALSE)\r\n\r\ncourse <- tibble(course_id           = 1:4,\r\n                 course_name         = paste(\"Course\", LETTERS[1:4]),\r\n                 start_date          = seq.Date(from = lubridate::as_date(\"2021-01-01\"), by = \"month\", length.out = 4),\r\n                 end_date            = lubridate::ceiling_date(start_date, unit = \"month\") - 1)\r\n\r\npaged_table(course)\r\n\r\n\r\n\r\n\r\nSecond Level Data: student\r\n\r\n\r\nset.seed(42)\r\nstudent <- tibble(s_id      = 1:20,\r\n                  s_name    = paste(\"Student\", LETTERS[1:20]),\r\n                  gender    = sample(c(\"X\",\"Y\",\"Z\"), 20, replace = TRUE),\r\n                  age       = sample(18:35, 20, replace = TRUE),\r\n                  course_id = sample(1:4, 20, replace = TRUE))\r\n\r\npaged_table(student)\r\n\r\n\r\n\r\n\r\nIf we are sourcing data from a database, it is probable that you would see these 2 levels of data in 2 separate tables/views, but most business users are comfortable with MS Excel and want all the data in one sheet!!\r\nSo the data actually looks something like this.\r\n\r\n\r\ncombined_df <- left_join(course, student, by = \"course_id\")\r\n\r\npaged_table(combined_df)\r\n\r\n\r\n\r\n\r\nDisplaying such data in a table causes all the top-level data fields to repeat for every second-level record. You can see that course_id, course_name, start_date and end_date columns repeat for all students who enrolled in the same course. Take a moment to think about how would you display such data in an interactive table in a web page, HTML report or Shiny app.\r\nIt is advisable to split such denormalized data into normalized data i.e.¬†create the original top-level and second level tables from the combined_df.\r\nVanilla reactable\r\nOne of my favorite R packages is {reactable}. The default output creates a neat interactive table with pagination (if data has more than 10 rows) and ability to sort columns.\r\n\r\n\r\nlibrary(reactable, quietly = TRUE, warn.conflicts = FALSE)\r\n\r\nreactable(data = combined_df)\r\n\r\n\r\n\r\nBasic Formatting\r\nWith some additional tweaks, we can make it look better.\r\n\r\n\r\nreactable(\r\n  data       = combined_df,\r\n  compact    = TRUE, # for minimum row height\r\n  filterable = TRUE, # for individual column filters\r\n  striped    = TRUE, # banded rows\r\n  resizable  = TRUE, # for resizable column widths\r\n  columns    = list( # define custom header name, width, alignment etc.\r\n    course_id   = colDef(name = \"CID\",         width = 50,  align = \"center\"),\r\n    course_name = colDef(name = \"Course Name\", width = 140),\r\n    start_date  = colDef(name = \"Start Date\",  width = 120, align = \"center\"),\r\n    end_date    = colDef(name = \"End Date\",    width = 120, align = \"center\"),\r\n    s_id        = colDef(name = \"SID\",         width = 70,  align = \"center\"),\r\n    s_name      = colDef(name = \"Student Name\"),\r\n    gender      = colDef(name = \"Gender\",      width = 80,  align = \"center\"),\r\n    age         = colDef(name = \"Age\",         width = 50)\r\n  )\r\n)\r\n\r\n\r\n\r\nHowever, the problem of repeating top-level fields still persists.\r\nGrouping and Aggregating\r\n{reactable} has a groupBy argument which lets us combined rows with common data fields and the aggregate argument inside colDef lets us define what aggregation to be used for each column of the top-level data.\r\n\r\n\r\nreactable(\r\n  data       = combined_df,\r\n  compact    = TRUE, # for minimum row height\r\n  filterable = TRUE, # for individual column filters\r\n  striped    = TRUE, # banded rows\r\n  resizable  = TRUE, # for resizable column widths\r\n  groupBy    = \"course_id\",\r\n  columns    = list(\r\n    # show count of students in each course\r\n    course_id   = colDef(name = \"CID\",         width = 100,  align = \"left\",    aggregate = \"count\"),  \r\n    # show unique course name\r\n    course_name = colDef(name = \"Course Name\", width = 140,                     aggregate = \"unique\"), \r\n    # show unique start date\r\n    start_date  = colDef(name = \"Start Date\",  width = 120,  align = \"center\",  aggregate = \"unique\"), \r\n    # show unique end date\r\n    end_date    = colDef(name = \"End Date\",    width = 120,  align = \"center\",  aggregate = \"unique\"), \r\n    s_id        = colDef(name = \"SID\",         width = 70,   align = \"center\"),\r\n    s_name      = colDef(name = \"Student Name\"),\r\n    gender      = colDef(name = \"Gender\",      width = 80,   align = \"center\"),\r\n    age         = colDef(name = \"Age\",         width = 50)\r\n  )\r\n)\r\n\r\n\r\n\r\nIn this case, all the columns which are not aggregated remain hidden. Clicking the little triangle in the CID column displays the hidden rows. Looks better, but again, the issue of duplicated data remains.\r\nYou can aggregate the second-level columns too, but this distorts the table and frankly, looks ugly. Here I aggregate the SID column in addition to all the other top-level columns.\r\n\r\n\r\nreactable(\r\n  data       = combined_df,\r\n  compact    = TRUE, # for minimum row height\r\n  filterable = TRUE, # for individual column filters\r\n  striped    = TRUE, # banded rows\r\n  resizable  = TRUE, # for resizable column widths\r\n  groupBy    = \"course_id\",\r\n  columns    = list(\r\n    course_id   = colDef(name = \"CID\",         width = 100,  align = \"left\",    aggregate = \"count\"),\r\n    course_name = colDef(name = \"Course Name\", width = 140,                     aggregate = \"unique\"),\r\n    start_date  = colDef(name = \"Start Date\",  width = 120,  align = \"center\",  aggregate = \"unique\"),\r\n    end_date    = colDef(name = \"End Date\",    width = 120,  align = \"center\",  aggregate = \"unique\"),\r\n    # YIKES!! Aggregating Student ID to show unique ids in each course.\r\n    s_id        = colDef(name = \"SID\",         width = 70,   align = \"center\",  aggregate = \"unique\"), \r\n    s_name      = colDef(name = \"Student Name\"),\r\n    gender      = colDef(name = \"Gender\",      width = 80,   align = \"center\"),\r\n    age         = colDef(name = \"Age\",         width = 50)\r\n  )\r\n)\r\n\r\n\r\n\r\nWouldn‚Äôt it be nice if we could display only the top-level columns by default and on clicking the small triangle for a row, show all the second-level columns corresponding to that row only, like a drill-down table?\r\nTo do this we need 2 separate tables. Earlier in this post, I said it is advisable to split such denormalized data into normalized data i.e.¬†create the original top-level and second level tables from the combined_df. Let‚Äôs recreate the 2 tables.\r\nI want to demonstrate how we go from the combined data to the 2 tables. Hence I will not use the course and student tables created earlier.\r\nCreating the top_level table using just the columns in course. Let‚Äôs also create a new column n_students depicting count of students in each course.\r\n\r\n\r\ntop_level <- combined_df %>% \r\n  # Only course info columns\r\n  count(course_id, course_name, start_date, end_date, name = \"n_students\") \r\n\r\npaged_table(top_level)\r\n\r\n\r\n\r\n\r\n\r\n\r\nsecond_level <- combined_df %>% \r\n  # Only Student info columns with unique identifier for Course\r\n  select(course_id, s_id, s_name, gender, age) %>% \r\n  arrange(s_id)\r\n\r\npaged_table(second_level)\r\n\r\n\r\n\r\n\r\nThe final Drill-down Table\r\nNow that we have the 2 tables ready, let us now create the final {reactable}. The trick here is to use the details argument to which we pass another {reactable} of just the rows with students data corresponding to given course.\r\n\r\n\r\nreactable(\r\n  data       = top_level,\r\n  compact    = TRUE, # for minimum row height\r\n  filterable = TRUE, # for individual column filters\r\n  striped    = TRUE, # banded rows\r\n  resizable  = TRUE, # for resizable column widths\r\n  columns    = list(\r\n    course_id   = colDef(name = \"CID\",             width = 50,  align = \"center\"),\r\n    course_name = colDef(name = \"Course Name\"), \r\n    start_date  = colDef(name = \"Start Date\",      width = 120, align = \"center\"),\r\n    end_date    = colDef(name = \"End Date\",        width = 120, align = \"center\"),\r\n    n_students  = colDef(name = \"No. of Students\", width = 130, align = \"center\")\r\n  ),\r\n  details = function(index) { # index is the row number of current row.\r\n    # sub-table of only those students for current row.\r\n    sec_lvl = second_level[second_level$course_id == top_level$course_id[index], ] \r\n    reactable(data       = sec_lvl,\r\n              compact    = TRUE, \r\n              filterable = TRUE,\r\n              bordered   = TRUE, \r\n              resizable  = TRUE,\r\n              columns    = list(\r\n                course_id   = colDef(show = FALSE), # hide the course id column\r\n                s_id        = colDef(name = \"SID\",    width = 70, align = \"center\"),\r\n                s_name      = colDef(name = \"Student Name\"),\r\n                gender      = colDef(name = \"Gender\", width = 90, align = \"center\"),\r\n                age         = colDef(name = \"Age\",    width = 50, align = \"center\")\r\n              )\r\n              )\r\n  }\r\n)\r\n\r\n\r\n\r\nSince the sub-table is also a {reactable}, you can go another level down‚Ä¶ and another, but please do consider the usability aspect of this feature before taking that decision. I haven‚Äôt tried going beyond 2 levels of data myself. Maybe a part 2 to this post??\r\nConclusion\r\nDrill-down tables let you pack a lot of data in a compact manner and allow use by multiple audiences interested in varying degrees/levels of information. {reactable} can help create an interactive data table from tabular data with sorting and pagination by default. The data table is an HTML widget that can be used in R Markdown documents and Shiny applications, or viewed from an R console. A lot of features can be enabled/disabled using the basic arguments of the reactable() function and much more using custom JavaScript.\r\nReferences & Citations\r\nGreg Lin (2020). reactable: Interactive Data Tables Based on ‚ÄòReact Table‚Äô. R package version 0.2.3. https://CRAN.R-project.org/package=reactable\r\n\r\n\r\n\r\n",
    "preview": "https://i.imgur.com/Zzk5SWf.gif",
    "last_modified": "2022-09-08T21:45:55+05:30",
    "input_file": {}
  },
  {
    "path": "posts/2021-07-17-programmingwithdplyr/",
    "title": "Programming with R {dplyr} - As I Understand It!!",
    "description": "How to create your own functions using {dplyr}",
    "author": [
      {
        "name": "Vishal Katti",
        "url": {}
      }
    ],
    "date": "2021-07-17",
    "categories": [
      "Rstats",
      "dplyr",
      "functions"
    ],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nInspiration\r\nData\r\n\r\nselect()\r\nPassing raw column names\r\nPassing multiple raw column names using ‚Ä¶ argument\r\nPassing a character vector of column names\r\n\r\nfilter()\r\nPassing single raw criteria\r\nPassing multiple raw criteria using ‚Ä¶ argument\r\nPassing single criteria as a character string\r\nPassing multiple criteria as character vector\r\n\r\nmutate()\r\nPassing the column name as raw name\r\nPassing the new variable name as character string (direct)\r\nPassing the new variable name as character string (indirect)\r\n\r\narrange()\r\nPassing single raw name\r\nPassing multiple raw names using ... argument\r\nPass single column name as string\r\nPass multiple column name as string\r\n\r\ngroup_by()\r\nPassing single raw name\r\nPassing multiple raw names using the ... operator\r\nPassing single or multiple column names as character string\r\n\r\n(Slightly Better) Examples\r\nmutate() example\r\ngroup_by() example\r\nMore ideas\r\n\r\nConclusion\r\nReferences\r\n\r\nIntroduction\r\nThe purpose of this document is to act as a quick guide for myself and others to understand how to use dplyr effectively to create dynamic functions. The general assumption is that the reader is familiar with the {dplyr} package and how to use it for data wrangling.\r\nIn this document, we will explore how to create functions using the popular dplyr verbs like select, filter, mutate, arrange and finally group_by with summarise.\r\nInspiration\r\nI regularly deal with event-related information with event date and few other columns like event type, root cause etc. Most reports usually involve calculating number of events that took place on a monthly, quarterly or annual basis, sometimes split by event type, root cause and other columns. After a few reports I realized that I am basically writing the same code over and over again to calculate these KPIs. Keeping the DRY (Don't Repeat Yourself) principle in mind, I managed to write a few functions to calculate these KPIs with a few dynamic variables. Following is an attempt to articulate what I learnt while creating those functions.\r\nData\r\nWe shall use the Texas Housing Sales data, available as a tibble in the popular ggplot2 package as reference data. It contains monthly information about the housing market in Texas provided by the TAMU real estate center, https://www.recenter.tamu.edu/. It has 8602 observations and 9 variables.\r\n\r\n\r\ntxhousing <- ggplot2::txhousing\r\ndplyr::glimpse(txhousing)\r\n\r\nRows: 8,602\r\nColumns: 9\r\n$ city      <chr> \"Abilene\", \"Abilene\", \"Abilene\", \"Abilene\", \"Abile~\r\n$ year      <int> 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 20~\r\n$ month     <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4,~\r\n$ sales     <dbl> 72, 98, 130, 98, 141, 156, 152, 131, 104, 101, 100~\r\n$ volume    <dbl> 5380000, 6505000, 9285000, 9730000, 10590000, 1391~\r\n$ median    <dbl> 71400, 58700, 58100, 68600, 67300, 66900, 73500, 7~\r\n$ listings  <dbl> 701, 746, 784, 785, 794, 780, 742, 765, 771, 764, ~\r\n$ inventory <dbl> 6.3, 6.6, 6.8, 6.9, 6.8, 6.6, 6.2, 6.4, 6.5, 6.6, ~\r\n$ date      <dbl> 2000.000, 2000.083, 2000.167, 2000.250, 2000.333, ~\r\n\r\nWe shall refer the above data in all the following sections.\r\nselect()\r\nWhen using dplyr functions, the two most popular ways to pass column names is either as bare names i.e.¬†column names without enclosing them in quotes like sales or volume OR pass them as a character string like ‚Äúsales‚Äù or ‚Äòvolume‚Äô. You could also pass a character vector like c(\"sales\", \"volume\"). In this section we will explore the 3 ways to dynamically select the columns we want.\r\nPassing raw column names\r\nIn this method, we pass the raw name of the column we want to select and use the embrace of curly-curly brackets to pass the raw name. For multiple columns, we can pass the raw names as a single vector.\r\n\r\n\r\nselect_raw <- function(df, var) {\r\n  dplyr::select(.data = df, {{var}}) %>%     # embrace of curly-curly {{}} brackets\r\n    head()                                   # to limit the number of output rows in this example.\r\n}\r\nselect_raw(txhousing, sales)                 # pass single raw name\r\n\r\n# A tibble: 6 x 1\r\n  sales\r\n  <dbl>\r\n1    72\r\n2    98\r\n3   130\r\n4    98\r\n5   141\r\n6   156\r\n\r\nselect_raw(txhousing, c(sales, volume))      # pass a vector of raw names for multiple columns\r\n\r\n# A tibble: 6 x 2\r\n  sales   volume\r\n  <dbl>    <dbl>\r\n1    72  5380000\r\n2    98  6505000\r\n3   130  9285000\r\n4    98  9730000\r\n5   141 10590000\r\n6   156 13910000\r\n\r\nIf passing multiple raw names as vector as in the select_raw() feels like an unnecessary complication, try the next method.\r\nPassing multiple raw column names using ‚Ä¶ argument\r\nIn this method, we use the . argument to pass the raw names of the columns we want to select.\r\n\r\n\r\nmy_select <- function(df, ...) {\r\n  dplyr::select(.data = df, ...) %>% \r\n    head()\r\n}\r\n\r\nmy_select(txhousing, sales, volume)          # pass multiple raw names directly\r\n\r\n# A tibble: 6 x 2\r\n  sales   volume\r\n  <dbl>    <dbl>\r\n1    72  5380000\r\n2    98  6505000\r\n3   130  9285000\r\n4    98  9730000\r\n5   141 10590000\r\n6   156 13910000\r\n\r\nPassing a character vector of column names\r\nIf we have the column names as a character vector, we use the all_of function to pass the character vector to the internal select function.\r\n\r\n\r\nmy_select_char <- function(df, cols) {\r\n  dplyr::select(.data = df, dplyr::all_of(cols)) %>% \r\n    head()\r\n}\r\n\r\nmy_cols <- c(\"sales\",\"volume\")\r\nmy_select_char(txhousing, my_cols)\r\n\r\n# A tibble: 6 x 2\r\n  sales   volume\r\n  <dbl>    <dbl>\r\n1    72  5380000\r\n2    98  6505000\r\n3   130  9285000\r\n4    98  9730000\r\n5   141 10590000\r\n6   156 13910000\r\n\r\nfilter()\r\nIn the previous section, we passed column names either as bare names or character strings. filter() takes one or more expressions/conditions that result in a logical vector, with same length as number of rows in the data.frame/tibble and returns only those rows for which the expression/condition returns TRUE. Following are 2 ways to pass these logical expressions/conditions. I‚Äôm using expression and condition interchangeably here. In this context, a condition is an expression that results in a boolean TRUE/FALSE result.\r\nPassing single raw criteria\r\nIn this method, we pass the condition sales > 8000 as a raw/bare expression.\r\n\r\n\r\nfilter_raw <- function(df, cond) {\r\n  dplyr::filter(.data = df, {{cond}})        # embrace of curly-curly {{}} brackets\r\n}\r\n\r\nfilter_raw(txhousing, sales > 8000)          # Pass a single raw criterion\r\n\r\n# A tibble: 10 x 9\r\n   city     year month sales     volume median listings invent~1  date\r\n   <chr>   <int> <int> <dbl>      <dbl>  <dbl>    <dbl>    <dbl> <dbl>\r\n 1 Houston  2006     5  8040 1602621368 151200    35398      5.5 2006.\r\n 2 Houston  2006     6  8628 1795898108 155200    36281      5.6 2006.\r\n 3 Houston  2013     5  8439 2121508529 186100    20526      3.3 2013.\r\n 4 Houston  2013     7  8468 2168720825 187800    21497      3.3 2014.\r\n 5 Houston  2013     8  8155 2083377894 186700    21366      3.3 2014.\r\n 6 Houston  2014     6  8391 2342443127 211200    19725      2.9 2014.\r\n 7 Houston  2014     7  8391 2278932511 199700    20214      3   2014.\r\n 8 Houston  2014     8  8167 2195184825 202400    20007      2.9 2015.\r\n 9 Houston  2015     6  8449 2490238594 222400    22311      3.2 2015.\r\n10 Houston  2015     7  8945 2568156780 217600    23875      3.4 2016.\r\n# ... with abbreviated variable name 1: inventory\r\n\r\nDo you think we can pass multiple bare conditions as a vector, like we did for select_raw() in the previous section? Let us try passing multiple raw criteria as a vector.\r\n\r\n\r\nfilter_raw(txhousing, c(sales > 8000, year > 2010))\r\n\r\nError in `dplyr::filter()`:\r\n! Problem while computing `..1 = c(sales > 8000, year >\r\n  2010)`.\r\nx Input `..1` must be of size 8602 or 1, not size 17204.\r\n\r\n\r\nPassing multiple raw criteria as a vector doesn‚Äôt work like it works for select_raw() function. Let us understand why. Consider the following code:\r\n\r\n\r\nA <- c(TRUE, TRUE)                           # boolean vector of length = 2\r\nB <- c(FALSE, FALSE)                         # boolean vector of length = 2\r\nX <- c(A, B)\r\nX\r\n\r\n[1]  TRUE  TRUE FALSE FALSE\r\n\r\nNotice that length of X is 4. Similarly, sales > 8000 evaluates to a TRUE/FALSE boolean vector of length 8602 (equal to number of rows in txhousing) and so does year > 2010. So the vector c(sales > 8000, year > 2010) becomes a TRUE/FALSE boolean vector of length 17204, which results in an error.\r\nPassing multiple raw criteria using ‚Ä¶ argument\r\nTo pass multiple raw criteria, we can use the ... argument.\r\n\r\n\r\nmy_filter <- function(df, ...) { \r\n  dplyr::filter(.data = df, ...)                # pass the dots argument\r\n  }\r\n\r\nmy_filter(txhousing, sales > 8000, year > 2010) # pass multiple raw criteria\r\n\r\n# A tibble: 8 x 9\r\n  city     year month sales     volume median listings inventory  date\r\n  <chr>   <int> <int> <dbl>      <dbl>  <dbl>    <dbl>     <dbl> <dbl>\r\n1 Houston  2013     5  8439 2121508529 186100    20526       3.3 2013.\r\n2 Houston  2013     7  8468 2168720825 187800    21497       3.3 2014.\r\n3 Houston  2013     8  8155 2083377894 186700    21366       3.3 2014.\r\n4 Houston  2014     6  8391 2342443127 211200    19725       2.9 2014.\r\n5 Houston  2014     7  8391 2278932511 199700    20214       3   2014.\r\n6 Houston  2014     8  8167 2195184825 202400    20007       2.9 2015.\r\n7 Houston  2015     6  8449 2490238594 222400    22311       3.2 2015.\r\n8 Houston  2015     7  8945 2568156780 217600    23875       3.4 2016.\r\n\r\nPassing single criteria as a character string\r\nBy default, dplyr::filter() does not accept conditions as character strings. Following is an example which results in error\r\n\r\n\r\ndplyr::filter(txhousing, \"sales > 8000\")\r\n\r\nError in `dplyr::filter()`:\r\n! Problem while computing `..1 = \"sales > 8000\"`.\r\nx Input `..1` must be a logical vector, not a character.\r\n\r\n\r\nWe need to convert the character condition into a raw expression.\r\n\r\n\r\nmy_filter_string <- function(df, cond) {\r\n  dplyr::filter(.data = df, eval(parse(text = cond)))   # convert text to raw criterion\r\n}\r\n\r\nmy_filter_string(txhousing, \"sales > 8000\")             # pass single text string as criteria\r\n\r\n# A tibble: 10 x 9\r\n   city     year month sales     volume median listings invent~1  date\r\n   <chr>   <int> <int> <dbl>      <dbl>  <dbl>    <dbl>    <dbl> <dbl>\r\n 1 Houston  2006     5  8040 1602621368 151200    35398      5.5 2006.\r\n 2 Houston  2006     6  8628 1795898108 155200    36281      5.6 2006.\r\n 3 Houston  2013     5  8439 2121508529 186100    20526      3.3 2013.\r\n 4 Houston  2013     7  8468 2168720825 187800    21497      3.3 2014.\r\n 5 Houston  2013     8  8155 2083377894 186700    21366      3.3 2014.\r\n 6 Houston  2014     6  8391 2342443127 211200    19725      2.9 2014.\r\n 7 Houston  2014     7  8391 2278932511 199700    20214      3   2014.\r\n 8 Houston  2014     8  8167 2195184825 202400    20007      2.9 2015.\r\n 9 Houston  2015     6  8449 2490238594 222400    22311      3.2 2015.\r\n10 Houston  2015     7  8945 2568156780 217600    23875      3.4 2016.\r\n# ... with abbreviated variable name 1: inventory\r\n\r\nThe special sauce here is the eval(parse(text = ...)) combo that converts the long text criteria into a single raw criteria and passes it to the internal filter() function.\r\nPassing multiple criteria as character vector\r\nWhat if want to pass multiple criteria as a string vector? In such a situation, we must combine all the string conditions into a single long string condition using paste0(..., collapse = \" & \"). The paste0(\"(\", cond, \")\", collapse = \" & \") combines all the criteria into a single long criteria, but still a text string.\r\n\r\n\r\nmy_filter_strings <- function(df, cond) { \r\n  filter_text <- paste0(\"(\", cond, \")\", collapse = \" & \")   # combine all criteria\r\n  message(\"Filter Condition: \", filter_text)                # (OPTIONAL) show the combined filter string\r\n  dplyr::filter(.data = df, eval(parse(text = filter_text)))# convert text to raw criterion\r\n  }\r\n\r\nmy_filter_criteria <- c(\"sales > 8000\", \"year > 2010\")\r\nmy_filter_strings(txhousing, my_filter_criteria)\r\n\r\n# A tibble: 8 x 9\r\n  city     year month sales     volume median listings inventory  date\r\n  <chr>   <int> <int> <dbl>      <dbl>  <dbl>    <dbl>     <dbl> <dbl>\r\n1 Houston  2013     5  8439 2121508529 186100    20526       3.3 2013.\r\n2 Houston  2013     7  8468 2168720825 187800    21497       3.3 2014.\r\n3 Houston  2013     8  8155 2083377894 186700    21366       3.3 2014.\r\n4 Houston  2014     6  8391 2342443127 211200    19725       2.9 2014.\r\n5 Houston  2014     7  8391 2278932511 199700    20214       3   2014.\r\n6 Houston  2014     8  8167 2195184825 202400    20007       2.9 2015.\r\n7 Houston  2015     6  8449 2490238594 222400    22311       3.2 2015.\r\n8 Houston  2015     7  8945 2568156780 217600    23875       3.4 2016.\r\n\r\n\r\n\r\nmy_filter_criteria_with_OR <- c(\"sales > 8000 | sales < 50\", \"year > 2010\")\r\n\r\n# NOTE: OR criteria must be a single string separated by pipe '|' as in example below.\r\nmy_filter_strings(txhousing, my_filter_criteria_with_OR)\r\n\r\n# A tibble: 315 x 9\r\n   city         year month sales  volume median listings inven~1  date\r\n   <chr>       <int> <int> <dbl>   <dbl>  <dbl>    <dbl>   <dbl> <dbl>\r\n 1 Brownsville  2011     1    48 4974408  83300      784    12.6 2011 \r\n 2 Brownsville  2011     2    47 5558575 101400      776    12.7 2011.\r\n 3 Brownsville  2011     7    47 4807019  91200      749    13.1 2012.\r\n 4 Brownsville  2011    12    39 4203440  86800      726    12.4 2012.\r\n 5 Brownsville  2012     1    43 3892348  85000      791    13.6 2012 \r\n 6 Brownsville  2012     3    27 2976148  93800      734    13.3 2012.\r\n 7 Brownsville  2012    11    41 5115393  99000      807    14   2013.\r\n 8 Brownsville  2013    11    38 4824930 108000      859    13.4 2014.\r\n 9 Brownsville  2015     1    41 5400796  97000      733    10.7 2015 \r\n10 Galveston    2011     1    43 8882961 170000     1015    13.7 2011 \r\n# ... with 305 more rows, and abbreviated variable name 1: inventory\r\n\r\nmutate()\r\nmutate() allows you to add new columns or modify existing columns. In the example below, we will create a new column volume_in_millions from the existing column volume. The names of both the columns can be passed to the function either as raw names or character strings.\r\nPassing the column name as raw name\r\n\r\n\r\nmutate_raw <- function(df, new_col_raw, old_col_raw, num = 1) { \r\n  dplyr::mutate(.data = df, {{new_col_raw}} := {{old_col_raw}}/num) %>% \r\n    head()\r\n}\r\n\r\ntxhousing %>% \r\n  select(city, year, month, volume) %>% \r\n  mutate_raw(vol_in_millions, volume, 1E6) # pass raw column names w/o quotes\r\n\r\n# A tibble: 6 x 5\r\n  city     year month   volume vol_in_millions\r\n  <chr>   <int> <int>    <dbl>           <dbl>\r\n1 Abilene  2000     1  5380000            5.38\r\n2 Abilene  2000     2  6505000            6.50\r\n3 Abilene  2000     3  9285000            9.28\r\n4 Abilene  2000     4  9730000            9.73\r\n5 Abilene  2000     5 10590000           10.6 \r\n6 Abilene  2000     6 13910000           13.9 \r\n\r\nPassing the new variable name as character string (direct)\r\n\r\n\r\nmutate_text <- function(df, new_col_str, old_col_str, num = 1) { \r\n  dplyr::mutate(.data = df, {{new_col_str}} := df[[old_col_str]]/num) %>% \r\n    head()\r\n}\r\n\r\ntxhousing %>% \r\n  select(city, year, month, volume) %>%\r\n  mutate_text(\"vol_in_millions\", \"volume\", 1E6) # pass column names as strings\r\n\r\n# A tibble: 6 x 5\r\n  city     year month   volume vol_in_millions\r\n  <chr>   <int> <int>    <dbl>           <dbl>\r\n1 Abilene  2000     1  5380000            5.38\r\n2 Abilene  2000     2  6505000            6.50\r\n3 Abilene  2000     3  9285000            9.28\r\n4 Abilene  2000     4  9730000            9.73\r\n5 Abilene  2000     5 10590000           10.6 \r\n6 Abilene  2000     6 13910000           13.9 \r\n\r\nPassing the new variable name as character string (indirect)\r\nInstead of passing the name of the variable as a character string as an argument, we can pass a variable containing the name of the variable. In the below example, the name of the new variable is stored in new_var. Using the new {glue} syntax, enabled by the walrus operator :=, we substitute the new_var variable with its value.\r\n\r\n\r\nmutate_var <- function(df, new_col_var, old_col_var, num = 1) {\r\n  dplyr::mutate(.data = df, \"{new_col_var}\" := df[[old_col_var]]/num) %>% \r\n    head()\r\n}\r\n\r\nnew_var <- \"vol_in_millions\"\r\nold_var <- \"volume\"\r\n\r\ntxhousing %>% \r\n  select(city, year, month, volume) %>%\r\n  mutate_var(new_var, old_var, 1E6)  # pass column names as variables\r\n\r\n# A tibble: 6 x 5\r\n  city     year month   volume vol_in_millions\r\n  <chr>   <int> <int>    <dbl>           <dbl>\r\n1 Abilene  2000     1  5380000            5.38\r\n2 Abilene  2000     2  6505000            6.50\r\n3 Abilene  2000     3  9285000            9.28\r\n4 Abilene  2000     4  9730000            9.73\r\n5 Abilene  2000     5 10590000           10.6 \r\n6 Abilene  2000     6 13910000           13.9 \r\n\r\narrange()\r\narrange() sorts the rows of a data frame by the values of selected columns. By default, it sorts in Ascending order. To force a column to sort in Descending order, we must use the desc() function.\r\nPassing single raw name\r\n\r\n\r\narrange_raw <- function(df, var) {\r\n  dplyr::arrange(.data = df, {{var}}) %>%    # embrace of curly-curly {{}} brackets\r\n    head()\r\n}\r\n\r\narrange_raw(txhousing, sales)\r\n\r\n# A tibble: 6 x 9\r\n  city            year month sales volume median listi~1 inven~2  date\r\n  <chr>          <int> <int> <dbl>  <dbl>  <dbl>   <dbl>   <dbl> <dbl>\r\n1 San Marcos      2011    10     6 1.16e6 180000     163     8.3 2012.\r\n2 Harlingen       2000     7     9 1.11e6  87500     719    30.8 2000.\r\n3 South Padre I~  2011     1     9 2.09e6 225000    1258    55.7 2011 \r\n4 San Marcos      2011     1    10 1.48e6 140000     165     7.5 2011 \r\n5 San Marcos      2011    12    10 1.56e6 140000     148     8   2012.\r\n6 San Marcos      2014    11    10 1.51e6 146700      96     4   2015.\r\n# ... with abbreviated variable names 1: listings, 2: inventory\r\n\r\narrange_raw(txhousing, desc(sales))\r\n\r\n# A tibble: 6 x 9\r\n  city     year month sales     volume median listings inventory  date\r\n  <chr>   <int> <int> <dbl>      <dbl>  <dbl>    <dbl>     <dbl> <dbl>\r\n1 Houston  2015     7  8945 2568156780 217600    23875       3.4 2016.\r\n2 Houston  2006     6  8628 1795898108 155200    36281       5.6 2006.\r\n3 Houston  2013     7  8468 2168720825 187800    21497       3.3 2014.\r\n4 Houston  2015     6  8449 2490238594 222400    22311       3.2 2015.\r\n5 Houston  2013     5  8439 2121508529 186100    20526       3.3 2013.\r\n6 Houston  2014     6  8391 2342443127 211200    19725       2.9 2014.\r\n\r\narrange_raw() fails when we pass multiple raw names as a vector.\r\n\r\n\r\narrange_raw(txhousing, c(sales, volume))\r\n\r\nError in `dplyr::arrange()`:\r\n! Problem with the implicit `transmute()` step.\r\nx Problem while computing `..1 = c(sales, volume)`.\r\nx `..1` must be size 8602 or 1, not 17204.\r\n\r\n\r\nPassing multiple raw names using ... argument\r\nTo pass multiple raw names, we must use the ... argument.\r\n\r\n\r\narrange_raw_multiple <- function(df, ...) {\r\n  dplyr::arrange(.data = df, ...) %>% \r\n    head()\r\n}\r\n\r\narrange_raw_multiple(txhousing, city, sales)\r\n\r\n# A tibble: 6 x 9\r\n  city     year month sales  volume median listings inventory  date\r\n  <chr>   <int> <int> <dbl>   <dbl>  <dbl>    <dbl>     <dbl> <dbl>\r\n1 Abilene  2003     1    68 5385000  70000      668       5.4  2003\r\n2 Abilene  2011     1    68 8834493 123300      809       6.1  2011\r\n3 Abilene  2009     1    70 8414801  92900      861       6.3  2009\r\n4 Abilene  2000     1    72 5380000  71400      701       6.3  2000\r\n5 Abilene  2010     1    73 9130783 112200      868       6.4  2010\r\n6 Abilene  2001     1    75 5730000  64500      779       6.8  2001\r\n\r\narrange_raw_multiple(txhousing, city, desc(sales))\r\n\r\n# A tibble: 6 x 9\r\n  city     year month sales   volume median listings inventory  date\r\n  <chr>   <int> <int> <dbl>    <dbl>  <dbl>    <dbl>     <dbl> <dbl>\r\n1 Abilene  2015     7   268 45845730 148700      986       5   2016.\r\n2 Abilene  2015     6   260 41396230 141500      965       5   2015.\r\n3 Abilene  2007     7   239 29315000 114300      940       5.2 2008.\r\n4 Abilene  2013     8   236 30777727 120000      976       5.4 2014.\r\n5 Abilene  2014     7   231 35861350 145800     1033       5.8 2014.\r\n6 Abilene  2005     6   230 24050000  92500      664       4.1 2005.\r\n\r\nPass single column name as string\r\n\r\n\r\narrange_str <- function(df, var, .desc = FALSE) {\r\n  if (.desc) {\r\n    dplyr::arrange(.data = df, desc(df[[var]])) %>% head()\r\n  } else {\r\n    dplyr::arrange(.data = df, df[[var]]) %>% head()\r\n  }\r\n}\r\n\r\narrange_str(txhousing, \"sales\")\r\n\r\n# A tibble: 6 x 9\r\n  city            year month sales volume median listi~1 inven~2  date\r\n  <chr>          <int> <int> <dbl>  <dbl>  <dbl>   <dbl>   <dbl> <dbl>\r\n1 San Marcos      2011    10     6 1.16e6 180000     163     8.3 2012.\r\n2 Harlingen       2000     7     9 1.11e6  87500     719    30.8 2000.\r\n3 South Padre I~  2011     1     9 2.09e6 225000    1258    55.7 2011 \r\n4 San Marcos      2011     1    10 1.48e6 140000     165     7.5 2011 \r\n5 San Marcos      2011    12    10 1.56e6 140000     148     8   2012.\r\n6 San Marcos      2014    11    10 1.51e6 146700      96     4   2015.\r\n# ... with abbreviated variable names 1: listings, 2: inventory\r\n\r\narrange_str(txhousing, \"sales\", .desc = TRUE)\r\n\r\n# A tibble: 6 x 9\r\n  city     year month sales     volume median listings inventory  date\r\n  <chr>   <int> <int> <dbl>      <dbl>  <dbl>    <dbl>     <dbl> <dbl>\r\n1 Houston  2015     7  8945 2568156780 217600    23875       3.4 2016.\r\n2 Houston  2006     6  8628 1795898108 155200    36281       5.6 2006.\r\n3 Houston  2013     7  8468 2168720825 187800    21497       3.3 2014.\r\n4 Houston  2015     6  8449 2490238594 222400    22311       3.2 2015.\r\n5 Houston  2013     5  8439 2121508529 186100    20526       3.3 2013.\r\n6 Houston  2014     6  8391 2342443127 211200    19725       2.9 2014.\r\n\r\nPass multiple column name as string\r\n\r\n\r\narrange_str_multiple <- function(df, var, desc = FALSE) {\r\n  if (desc) {\r\n    dplyr::arrange(.data = df, desc(df[var])) %>% head()\r\n  } else {\r\n    dplyr::arrange(.data = df, df[var]) %>% head()\r\n  }\r\n}\r\n\r\n# This function arranges the dataframe either all ascending\r\n# or all descending. Definitely need a better example.\r\n\r\narrange_str_multiple(txhousing, c(\"year\", \"month\", \"sales\"))\r\n\r\n# A tibble: 6 x 9\r\n  city         year month sales  volume median listings invent~1  date\r\n  <chr>       <int> <int> <dbl>   <dbl>  <dbl>    <dbl>    <dbl> <dbl>\r\n1 Paris        2000     1    19 1440000  71700      286      7.5  2000\r\n2 San Marcos   2000     1    22 2380000 106700      190      6.3  2000\r\n3 Lufkin       2000     1    28 2280000  68000       NA     NA    2000\r\n4 Harlingen    2000     1    31 3910000  87500      644     24.9  2000\r\n5 Galveston    2000     1    37 4555000  95000      636      9.1  2000\r\n6 Port Arthur  2000     1    40 3090000  68300      314      5.6  2000\r\n# ... with abbreviated variable name 1: inventory\r\n\r\narrange_str_multiple(txhousing, c(\"year\", \"month\", \"sales\"), desc = TRUE)\r\n\r\n# A tibble: 6 x 9\r\n  city           year month sales  volume median listi~1 inven~2  date\r\n  <chr>         <int> <int> <dbl>   <dbl>  <dbl>   <dbl>   <dbl> <dbl>\r\n1 Houston        2015     7  8945  2.57e9 217600   23875     3.4 2016.\r\n2 Dallas         2015     7  7038  2.02e9 233000   12292     2.4 2016.\r\n3 Austin         2015     7  3466  1.15e9 264600    7913     3   2016.\r\n4 San Antonio    2015     7  2962  7.05e8 198100    9462     4.1 2016.\r\n5 Collin County  2015     7  1861  6.14e8 292600    2809     2.1 2016.\r\n6 Fort Bend      2015     7  1372  4.32e8 280400    3328     3.1 2016.\r\n# ... with abbreviated variable names 1: listings, 2: inventory\r\n\r\ngroup_by()\r\nIn group_by(), we select which columns to, well, group by! (Damn these well-named functions!). So one can use the same techniques as select() to choose the columns.\r\nIn the following examples, we will create only one summarised value total_sales for simplicity.\r\nPassing single raw name\r\n\r\n\r\ngroup_raw <- function(df, grp) {\r\n  df %>% \r\n    group_by({{grp}}) %>% \r\n    summarise(total_sales = sum(sales, na.rm = TRUE),\r\n              .groups = 'drop')  %>% \r\n    head(n=5)\r\n}\r\n\r\ngroup_raw(txhousing, year)        # Sum of sales per year\r\n\r\n# A tibble: 5 x 2\r\n   year total_sales\r\n  <int>       <dbl>\r\n1  2000      222483\r\n2  2001      231453\r\n3  2002      234600\r\n4  2003      253909\r\n5  2004      283999\r\n\r\ngroup_raw(txhousing, month)       # Sum of sales per month\r\n\r\n# A tibble: 5 x 2\r\n  month total_sales\r\n  <int>       <dbl>\r\n1     1      245924\r\n2     2      296410\r\n3     3      386909\r\n4     4      397332\r\n5     5      448968\r\n\r\nPassing multiple raw names using the ... operator\r\n\r\n\r\ngroup_raw_multiple <- function(df, ...) {\r\n  df %>% \r\n    group_by(...) %>% \r\n    summarise(total_sales = sum(sales, na.rm = TRUE),\r\n              .groups = 'drop')  %>% \r\n    head(n = 5)\r\n}\r\n\r\ngroup_raw_multiple(txhousing, year)              # Sum of sales per year\r\n\r\n# A tibble: 5 x 2\r\n   year total_sales\r\n  <int>       <dbl>\r\n1  2000      222483\r\n2  2001      231453\r\n3  2002      234600\r\n4  2003      253909\r\n5  2004      283999\r\n\r\ngroup_raw_multiple(txhousing, year, month)       # Sum of sales per month\r\n\r\n# A tibble: 5 x 3\r\n   year month total_sales\r\n  <int> <int>       <dbl>\r\n1  2000     1       11411\r\n2  2000     2       15674\r\n3  2000     3       20202\r\n4  2000     4       18658\r\n5  2000     5       22388\r\n\r\nPassing single or multiple column names as character string\r\n\r\n\r\ngroup_str <- function(df, grp) {\r\n  df %>% \r\n    group_by(df[grp]) %>% \r\n    summarise(total_sales = sum(sales, na.rm = TRUE),\r\n              .groups = 'drop')  %>% \r\n    head(n=5)\r\n}\r\n\r\ngroup_str(txhousing, \"year\")                   # Sum of sales per year\r\n\r\n# A tibble: 5 x 2\r\n   year total_sales\r\n  <int>       <dbl>\r\n1  2000      222483\r\n2  2001      231453\r\n3  2002      234600\r\n4  2003      253909\r\n5  2004      283999\r\n\r\ngroup_str(txhousing, c(\"year\", \"month\"))       # Sum of sales per month\r\n\r\n# A tibble: 5 x 3\r\n   year month total_sales\r\n  <int> <int>       <dbl>\r\n1  2000     1       11411\r\n2  2000     2       15674\r\n3  2000     3       20202\r\n4  2000     4       18658\r\n5  2000     5       22388\r\n\r\n# The same column names can be passed as variables containing the character names\r\nyr <- \"year\"\r\ngroup_str(txhousing, yr)\r\n\r\n# A tibble: 5 x 2\r\n   year total_sales\r\n  <int>       <dbl>\r\n1  2000      222483\r\n2  2001      231453\r\n3  2002      234600\r\n4  2003      253909\r\n5  2004      283999\r\n\r\nyrmon <- c(\"year\", \"month\")\r\ngroup_str(txhousing, yrmon)\r\n\r\n# A tibble: 5 x 3\r\n   year month total_sales\r\n  <int> <int>       <dbl>\r\n1  2000     1       11411\r\n2  2000     2       15674\r\n3  2000     3       20202\r\n4  2000     4       18658\r\n5  2000     5       22388\r\n\r\nIf you want the summarise column to have a custom name like total_<sumvar>, then you can wrap the value in quotes as below. This method uses the glue syntax enabled by the := walrus operator. The walrus operator takes either a raw name or a character string on its LHS.\r\n\r\n\r\ngroup_raw2 <- function(df, grp, sumvar) {\r\n  df %>% \r\n    group_by({{grp}}) %>% \r\n    summarise(\"total_{{sumvar}}\" := sum({{sumvar}}, na.rm = TRUE),\r\n              .groups = 'drop')  %>% \r\n    head(n=5)\r\n}\r\n\r\ngroup_raw2(txhousing, year, sales)            # Sum of sales per year\r\n\r\n# A tibble: 5 x 2\r\n   year total_sales\r\n  <int>       <dbl>\r\n1  2000      222483\r\n2  2001      231453\r\n3  2002      234600\r\n4  2003      253909\r\n5  2004      283999\r\n\r\ngroup_raw2(txhousing, month, listings)        # Sum of listings per month\r\n\r\n# A tibble: 5 x 2\r\n  month total_listings\r\n  <int>          <dbl>\r\n1     1        1854661\r\n2     2        1888104\r\n3     3        1949187\r\n4     4        1991278\r\n5     5        2038932\r\n\r\nAfter writing so many examples, I see a pattern. group_by() works with techniques similar to select() while summarise() works with techniques similar to mutate().\r\n(Slightly Better) Examples\r\nThe txhousing is a city-wise monthly sales and volume dataset. It has a year and month column. Let us create a date column and keep only those columns relevant for our custom tx_summary() function.\r\n\r\n\r\nsmall_df <- txhousing %>% \r\n  mutate(date = lubridate::as_date(glue::glue(\"{year}-{month}-01\"))) %>% \r\n  select(city, date, sales, volume)\r\n\r\n\r\nmutate() example\r\nNow let us create the create_ymq() function. This function would take 2 arguments, a data frame df and a raw name of a date column.\r\n\r\n\r\ncreate_ymq <- function(df, date_col) {\r\n  stopifnot(inherits(df, \"data.frame\"))\r\n  stopifnot(class(df %>% dplyr::pull({{date_col}})) == 'Date')\r\n  dplyr::mutate(df,\r\n                Year = lubridate::year({{date_col}}),\r\n                nHalf = lubridate::semester({{date_col}}),\r\n                yHalf = lubridate::semester({{date_col}}, with_year = TRUE),\r\n                dHalf = paste0(lubridate::semester({{date_col}}), \"H\", format({{date_col}},\"%y\")),\r\n                nQtr = lubridate::quarter({{date_col}}),\r\n                yQtr = lubridate::quarter({{date_col}}, with_year = TRUE),\r\n                dQtr = paste0(lubridate::quarter({{date_col}}),\"Q\", format({{date_col}},\"%y\")),\r\n                Month = lubridate::month({{date_col}}),\r\n                yMonth = as.numeric(format({{date_col}}, \"%Y.%m\")),\r\n                dMonth = format({{date_col}}, \"%b %Y\")\r\n                )\r\n}\r\n\r\ncreate_ymq(df = small_df, date_col = date) %>% glimpse()\r\n\r\nRows: 8,602\r\nColumns: 14\r\n$ city   <chr> \"Abilene\", \"Abilene\", \"Abilene\", \"Abilene\", \"Abilene\"~\r\n$ date   <date> 2000-01-01, 2000-02-01, 2000-03-01, 2000-04-01, 2000~\r\n$ sales  <dbl> 72, 98, 130, 98, 141, 156, 152, 131, 104, 101, 100, 9~\r\n$ volume <dbl> 5380000, 6505000, 9285000, 9730000, 10590000, 1391000~\r\n$ Year   <dbl> 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000,~\r\n$ nHalf  <int> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1,~\r\n$ yHalf  <dbl> 2000.1, 2000.1, 2000.1, 2000.1, 2000.1, 2000.1, 2000.~\r\n$ dHalf  <chr> \"1H00\", \"1H00\", \"1H00\", \"1H00\", \"1H00\", \"1H00\", \"2H00~\r\n$ nQtr   <int> 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 2,~\r\n$ yQtr   <dbl> 2000.1, 2000.1, 2000.1, 2000.2, 2000.2, 2000.2, 2000.~\r\n$ dQtr   <chr> \"1Q00\", \"1Q00\", \"1Q00\", \"2Q00\", \"2Q00\", \"2Q00\", \"3Q00~\r\n$ Month  <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5,~\r\n$ yMonth <dbl> 2000.01, 2000.02, 2000.03, 2000.04, 2000.05, 2000.06,~\r\n$ dMonth <chr> \"Jan 2000\", \"Feb 2000\", \"Mar 2000\", \"Apr 2000\", \"May ~\r\n\r\ngroup_by() example\r\nNow that we have a function that creates various date-related columns, let us create a function that let‚Äôs you create summary tables like annual sales per city, quarterly volumes per city etc.\r\n\r\n\r\ntx_summary <- function(df, grp_col, sum_col) {\r\n  df %>% \r\n    group_by(city, {{grp_col}}) %>% \r\n    summarise(\"total_{{sum_col}}\" := sum({{sum_col}}, na.rm = TRUE), .groups = 'drop')\r\n}\r\n\r\n\r\nUsing these 2 functions, we can now create multiple summary tables\r\n\r\n\r\nsmall_df_with_date_cols <- small_df %>% create_ymq(date_col = date)\r\n\r\n# Annual Sales per city\r\nsmall_df_with_date_cols %>% tx_summary(grp_col = Year, sum_col = sales)\r\n\r\n# A tibble: 736 x 3\r\n   city     Year total_sales\r\n   <chr>   <dbl>       <dbl>\r\n 1 Abilene  2000        1375\r\n 2 Abilene  2001        1431\r\n 3 Abilene  2002        1516\r\n 4 Abilene  2003        1632\r\n 5 Abilene  2004        1830\r\n 6 Abilene  2005        1977\r\n 7 Abilene  2006        1997\r\n 8 Abilene  2007        2003\r\n 9 Abilene  2008        1651\r\n10 Abilene  2009        1634\r\n# ... with 726 more rows\r\n\r\n# Half Yearly volumes per city\r\nsmall_df_with_date_cols %>% tx_summary(grp_col = yHalf, sum_col = volume)\r\n\r\n# A tibble: 1,472 x 3\r\n   city    yHalf total_volume\r\n   <chr>   <dbl>        <dbl>\r\n 1 Abilene 2000.     55400000\r\n 2 Abilene 2000.     53175000\r\n 3 Abilene 2001.     55795000\r\n 4 Abilene 2001.     58570000\r\n 5 Abilene 2002.     55305000\r\n 6 Abilene 2002.     63370000\r\n 7 Abilene 2003.     58175000\r\n 8 Abilene 2003.     77500000\r\n 9 Abilene 2004.     74205000\r\n10 Abilene 2004.     85465000\r\n# ... with 1,462 more rows\r\n\r\n# Quarterly Sales per city\r\nsmall_df_with_date_cols %>% tx_summary(grp_col = yQtr, sum_col = sales)\r\n\r\n# A tibble: 2,898 x 3\r\n   city     yQtr total_sales\r\n   <chr>   <dbl>       <dbl>\r\n 1 Abilene 2000.         300\r\n 2 Abilene 2000.         395\r\n 3 Abilene 2000.         387\r\n 4 Abilene 2000.         293\r\n 5 Abilene 2001.         305\r\n 6 Abilene 2001.         394\r\n 7 Abilene 2001.         401\r\n 8 Abilene 2001.         331\r\n 9 Abilene 2002.         295\r\n10 Abilene 2002.         425\r\n# ... with 2,888 more rows\r\n\r\n# Monthly Volumes per city\r\nsmall_df_with_date_cols %>% tx_summary(grp_col = yMonth, sum_col = volume)\r\n\r\n# A tibble: 8,602 x 3\r\n   city    yMonth total_volume\r\n   <chr>    <dbl>        <dbl>\r\n 1 Abilene  2000.      5380000\r\n 2 Abilene  2000.      6505000\r\n 3 Abilene  2000.      9285000\r\n 4 Abilene  2000.      9730000\r\n 5 Abilene  2000.     10590000\r\n 6 Abilene  2000.     13910000\r\n 7 Abilene  2000.     12635000\r\n 8 Abilene  2000.     10710000\r\n 9 Abilene  2000.      7615000\r\n10 Abilene  2000.      7040000\r\n# ... with 8,592 more rows\r\n\r\nMore ideas\r\nYou could further extend this by creating a custom filtering function that gives you, say, the rows with the highest or lowest total_sales or total_volume.\r\nConclusion\r\nThe ability to create such dynamic functions, enabled by the wonderful {dplyr} package, allows us to level-up in terms of programming with R and helps make our code neat and tidy.\r\nHow I feel while creating custom functions with {dplyr}! I can almost hear the music! Source: imgur.comReferences\r\nHadley Wickham, Romain Fran√ßois, Lionel Henry and Kirill M√ºller (2022).\r\ndplyr: A Grammar of Data Manipulation. R package version 1.0.9.\r\nhttps://CRAN.R-project.org/package=dplyr\r\nhttps://dplyr.tidyverse.org/articles/programming.html\r\nH. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New\r\nYork, 2016. https://ggplot2.tidyverse.org\r\nJim Hester and Jennifer Bryan (2022). glue: Interpreted String Literals. R\r\npackage version 1.6.2. https://CRAN.R-project.org/package=glue\r\n\r\n\r\n\r\n",
    "preview": "https://i.imgur.com/H9jo8OB.gif",
    "last_modified": "2022-09-08T21:44:16+05:30",
    "input_file": {}
  }
]
